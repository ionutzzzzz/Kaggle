{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec83e7b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:25.410011Z",
     "iopub.status.busy": "2024-11-09T18:37:25.409554Z",
     "iopub.status.idle": "2024-11-09T18:37:25.703057Z",
     "shell.execute_reply": "2024-11-09T18:37:25.701951Z"
    },
    "papermill": {
     "duration": 0.307837,
     "end_time": "2024-11-09T18:37:25.705644",
     "exception": false,
     "start_time": "2024-11-09T18:37:25.397807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/depression-surveydataset-for-analysis/final_depression_dataset_1.csv\n",
      "/kaggle/input/playground-series-s4e11/sample_submission.csv\n",
      "/kaggle/input/playground-series-s4e11/train.csv\n",
      "/kaggle/input/playground-series-s4e11/test.csv\n"
     ]
    }
   ],
   "source": [
    "import polars as pl # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pl.Config.set_tbl_cols(20)\n",
    "pl.Config.set_tbl_rows(30)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbbbabd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:25.726124Z",
     "iopub.status.busy": "2024-11-09T18:37:25.725293Z",
     "iopub.status.idle": "2024-11-09T18:37:26.040074Z",
     "shell.execute_reply": "2024-11-09T18:37:26.038805Z"
    },
    "papermill": {
     "duration": 0.327351,
     "end_time": "2024-11-09T18:37:26.042341",
     "exception": false,
     "start_time": "2024-11-09T18:37:25.714990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([('id', Int64),\n",
       "        ('Name', String),\n",
       "        ('Gender', String),\n",
       "        ('Age', Float64),\n",
       "        ('City', String),\n",
       "        ('Working Professional or Student', String),\n",
       "        ('Profession', String),\n",
       "        ('Academic Pressure', Float64),\n",
       "        ('Work Pressure', Float64),\n",
       "        ('CGPA', Float64),\n",
       "        ('Study Satisfaction', Float64),\n",
       "        ('Job Satisfaction', Float64),\n",
       "        ('Sleep Duration', String),\n",
       "        ('Dietary Habits', String),\n",
       "        ('Degree', String),\n",
       "        ('Have you ever had suicidal thoughts ?', String),\n",
       "        ('Work/Study Hours', Float64),\n",
       "        ('Financial Stress', Float64),\n",
       "        ('Family History of Mental Illness', String),\n",
       "        ('Depression', Int64)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>Name</th><th>Gender</th><th>Age</th><th>City</th><th>Working Professional or Student</th><th>Profession</th><th>Academic Pressure</th><th>Work Pressure</th><th>CGPA</th><th>Study Satisfaction</th><th>Job Satisfaction</th><th>Sleep Duration</th><th>Dietary Habits</th><th>Degree</th><th>Have you ever had suicidal thoughts ?</th><th>Work/Study Hours</th><th>Financial Stress</th><th>Family History of Mental Illness</th><th>Depression</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;Aaradhya&quot;</td><td>&quot;Female&quot;</td><td>49.0</td><td>&quot;Ludhiana&quot;</td><td>&quot;Working Professional&quot;</td><td>&quot;Chef&quot;</td><td>null</td><td>5.0</td><td>null</td><td>null</td><td>2.0</td><td>&quot;More than 8 hours&quot;</td><td>&quot;Healthy&quot;</td><td>&quot;BHM&quot;</td><td>&quot;No&quot;</td><td>1.0</td><td>2.0</td><td>&quot;No&quot;</td><td>0</td></tr><tr><td>1</td><td>&quot;Vivan&quot;</td><td>&quot;Male&quot;</td><td>26.0</td><td>&quot;Varanasi&quot;</td><td>&quot;Working Professional&quot;</td><td>&quot;Teacher&quot;</td><td>null</td><td>4.0</td><td>null</td><td>null</td><td>3.0</td><td>&quot;Less than 5 hours&quot;</td><td>&quot;Unhealthy&quot;</td><td>&quot;LLB&quot;</td><td>&quot;Yes&quot;</td><td>7.0</td><td>3.0</td><td>&quot;No&quot;</td><td>1</td></tr><tr><td>2</td><td>&quot;Yuvraj&quot;</td><td>&quot;Male&quot;</td><td>33.0</td><td>&quot;Visakhapatnam&quot;</td><td>&quot;Student&quot;</td><td>null</td><td>5.0</td><td>null</td><td>8.97</td><td>2.0</td><td>null</td><td>&quot;5-6 hours&quot;</td><td>&quot;Healthy&quot;</td><td>&quot;B.Pharm&quot;</td><td>&quot;Yes&quot;</td><td>3.0</td><td>1.0</td><td>&quot;No&quot;</td><td>1</td></tr><tr><td>3</td><td>&quot;Yuvraj&quot;</td><td>&quot;Male&quot;</td><td>22.0</td><td>&quot;Mumbai&quot;</td><td>&quot;Working Professional&quot;</td><td>&quot;Teacher&quot;</td><td>null</td><td>5.0</td><td>null</td><td>null</td><td>1.0</td><td>&quot;Less than 5 hours&quot;</td><td>&quot;Moderate&quot;</td><td>&quot;BBA&quot;</td><td>&quot;Yes&quot;</td><td>10.0</td><td>1.0</td><td>&quot;Yes&quot;</td><td>1</td></tr><tr><td>4</td><td>&quot;Rhea&quot;</td><td>&quot;Female&quot;</td><td>30.0</td><td>&quot;Kanpur&quot;</td><td>&quot;Working Professional&quot;</td><td>&quot;Business Analyst&quot;</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>1.0</td><td>&quot;5-6 hours&quot;</td><td>&quot;Unhealthy&quot;</td><td>&quot;BBA&quot;</td><td>&quot;Yes&quot;</td><td>9.0</td><td>4.0</td><td>&quot;Yes&quot;</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 20)\n",
       "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
       "│ id  ┆ Nam ┆ Gen ┆ Age ┆ Cit ┆ Wor ┆ Pro ┆ Aca ┆ Wor ┆ CGP ┆ Stu ┆ Job ┆ Sle ┆ Die ┆ Deg ┆ Hav ┆ Wor ┆ Fin ┆ Fam ┆ Dep │\n",
       "│ --- ┆ e   ┆ der ┆ --- ┆ y   ┆ kin ┆ fes ┆ dem ┆ k   ┆ A   ┆ dy  ┆ Sat ┆ ep  ┆ tar ┆ ree ┆ e   ┆ k/S ┆ anc ┆ ily ┆ res │\n",
       "│ i64 ┆ --- ┆ --- ┆ f64 ┆ --- ┆ g   ┆ sio ┆ ic  ┆ Pre ┆ --- ┆ Sat ┆ isf ┆ Dur ┆ y   ┆ --- ┆ you ┆ tud ┆ ial ┆ His ┆ sio │\n",
       "│     ┆ str ┆ str ┆     ┆ str ┆ Pro ┆ n   ┆ Pre ┆ ssu ┆ f64 ┆ isf ┆ act ┆ ati ┆ Hab ┆ str ┆ eve ┆ y   ┆ Str ┆ tor ┆ n   │\n",
       "│     ┆     ┆     ┆     ┆     ┆ fes ┆ --- ┆ ssu ┆ re  ┆     ┆ act ┆ ion ┆ on  ┆ its ┆     ┆ r   ┆ Hou ┆ ess ┆ y   ┆ --- │\n",
       "│     ┆     ┆     ┆     ┆     ┆ sio ┆ str ┆ re  ┆ --- ┆     ┆ ion ┆ --- ┆ --- ┆ --- ┆     ┆ had ┆ rs  ┆ --- ┆ of  ┆ i64 │\n",
       "│     ┆     ┆     ┆     ┆     ┆ nal ┆     ┆ --- ┆ f64 ┆     ┆ --- ┆ f64 ┆ str ┆ str ┆     ┆ sui ┆ --- ┆ f64 ┆ Men ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ or  ┆     ┆ f64 ┆     ┆     ┆ f64 ┆     ┆     ┆     ┆     ┆ cid ┆ f64 ┆     ┆ tal ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ Stu ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ al  ┆     ┆     ┆ Ill ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ den ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ tho ┆     ┆     ┆ ne… ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ …   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ …   ┆     ┆     ┆ --- ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ --- ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ --- ┆     ┆     ┆ str ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ str ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ str ┆     ┆     ┆     ┆     │\n",
       "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
       "│ 0   ┆ Aar ┆ Fem ┆ 49. ┆ Lud ┆ Wor ┆ Che ┆ nul ┆ 5.0 ┆ nul ┆ nul ┆ 2.0 ┆ Mor ┆ Hea ┆ BHM ┆ No  ┆ 1.0 ┆ 2.0 ┆ No  ┆ 0   │\n",
       "│     ┆ adh ┆ ale ┆ 0   ┆ hia ┆ kin ┆ f   ┆ l   ┆     ┆ l   ┆ l   ┆     ┆ e   ┆ lth ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆ ya  ┆     ┆     ┆ na  ┆ g   ┆     ┆     ┆     ┆     ┆     ┆     ┆ tha ┆ y   ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ Pro ┆     ┆     ┆     ┆     ┆     ┆     ┆ n 8 ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ fes ┆     ┆     ┆     ┆     ┆     ┆     ┆ hou ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ sio ┆     ┆     ┆     ┆     ┆     ┆     ┆ rs  ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ nal ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 1   ┆ Viv ┆ Mal ┆ 26. ┆ Var ┆ Wor ┆ Tea ┆ nul ┆ 4.0 ┆ nul ┆ nul ┆ 3.0 ┆ Les ┆ Unh ┆ LLB ┆ Yes ┆ 7.0 ┆ 3.0 ┆ No  ┆ 1   │\n",
       "│     ┆ an  ┆ e   ┆ 0   ┆ ana ┆ kin ┆ che ┆ l   ┆     ┆ l   ┆ l   ┆     ┆ s   ┆ eal ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆ si  ┆ g   ┆ r   ┆     ┆     ┆     ┆     ┆     ┆ tha ┆ thy ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ Pro ┆     ┆     ┆     ┆     ┆     ┆     ┆ n 5 ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ fes ┆     ┆     ┆     ┆     ┆     ┆     ┆ hou ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ sio ┆     ┆     ┆     ┆     ┆     ┆     ┆ rs  ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ nal ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 2   ┆ Yuv ┆ Mal ┆ 33. ┆ Vis ┆ Stu ┆ nul ┆ 5.0 ┆ nul ┆ 8.9 ┆ 2.0 ┆ nul ┆ 5-6 ┆ Hea ┆ B.P ┆ Yes ┆ 3.0 ┆ 1.0 ┆ No  ┆ 1   │\n",
       "│     ┆ raj ┆ e   ┆ 0   ┆ akh ┆ den ┆ l   ┆     ┆ l   ┆ 7   ┆     ┆ l   ┆ hou ┆ lth ┆ har ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆ apa ┆ t   ┆     ┆     ┆     ┆     ┆     ┆     ┆ rs  ┆ y   ┆ m   ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆ tna ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆ m   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 3   ┆ Yuv ┆ Mal ┆ 22. ┆ Mum ┆ Wor ┆ Tea ┆ nul ┆ 5.0 ┆ nul ┆ nul ┆ 1.0 ┆ Les ┆ Mod ┆ BBA ┆ Yes ┆ 10. ┆ 1.0 ┆ Yes ┆ 1   │\n",
       "│     ┆ raj ┆ e   ┆ 0   ┆ bai ┆ kin ┆ che ┆ l   ┆     ┆ l   ┆ l   ┆     ┆ s   ┆ era ┆     ┆     ┆ 0   ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ g   ┆ r   ┆     ┆     ┆     ┆     ┆     ┆ tha ┆ te  ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ Pro ┆     ┆     ┆     ┆     ┆     ┆     ┆ n 5 ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ fes ┆     ┆     ┆     ┆     ┆     ┆     ┆ hou ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ sio ┆     ┆     ┆     ┆     ┆     ┆     ┆ rs  ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ nal ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 4   ┆ Rhe ┆ Fem ┆ 30. ┆ Kan ┆ Wor ┆ Bus ┆ nul ┆ 1.0 ┆ nul ┆ nul ┆ 1.0 ┆ 5-6 ┆ Unh ┆ BBA ┆ Yes ┆ 9.0 ┆ 4.0 ┆ Yes ┆ 0   │\n",
       "│     ┆ a   ┆ ale ┆ 0   ┆ pur ┆ kin ┆ ine ┆ l   ┆     ┆ l   ┆ l   ┆     ┆ hou ┆ eal ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ g   ┆ ss  ┆     ┆     ┆     ┆     ┆     ┆ rs  ┆ thy ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ Pro ┆ Ana ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ fes ┆ lys ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ sio ┆ t   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆ nal ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pl.scan_csv('/kaggle/input/playground-series-s4e11/train.csv').collect()\n",
    "test_df = pl.scan_csv('/kaggle/input/playground-series-s4e11/test.csv').collect()\n",
    "sample_df = pl.scan_csv('/kaggle/input/playground-series-s4e11/sample_submission.csv').collect()\n",
    "# https://www.kaggle.com/datasets/sumansharmadataworld/depression-surveydataset-for-analysis need to \"add input\" for kaggle \n",
    "# cloud environment, \n",
    "# adding the original seams to have a lower score  \n",
    "# original_df = pl.scan_csv ('/kaggle/input/depression-surveydataset-for-analysis/final_depression_dataset_1.csv').collect()\n",
    "display  (train_df.collect_schema())                       \n",
    "display (train_df.head(5))\n",
    "#display  (original_df.collect_schema())                       \n",
    "# display (original_df.head(5))                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f893a70",
   "metadata": {
    "papermill": {
     "duration": 0.009134,
     "end_time": "2024-11-09T18:37:26.060977",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.051843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exporatory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5edc1df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:26.081746Z",
     "iopub.status.busy": "2024-11-09T18:37:26.081331Z",
     "iopub.status.idle": "2024-11-09T18:37:26.262022Z",
     "shell.execute_reply": "2024-11-09T18:37:26.260920Z"
    },
    "papermill": {
     "duration": 0.194047,
     "end_time": "2024-11-09T18:37:26.264359",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.070312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Name</th><th>Depression</th><th>id</th></tr><tr><td>str</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Sanya&quot;</td><td>0.147013</td><td>1272</td></tr><tr><td>&quot;Anushka&quot;</td><td>0.213448</td><td>1279</td></tr><tr><td>&quot;Ritika&quot;</td><td>0.126428</td><td>1313</td></tr><tr><td>&quot;Vidya&quot;</td><td>0.200284</td><td>1408</td></tr><tr><td>&quot;Ansh&quot;</td><td>0.152495</td><td>1423</td></tr><tr><td>&quot;Ishaani&quot;</td><td>0.144888</td><td>1477</td></tr><tr><td>&quot;Anand&quot;</td><td>0.312248</td><td>1486</td></tr><tr><td>&quot;Raunak&quot;</td><td>0.185039</td><td>1524</td></tr><tr><td>&quot;Rashi&quot;</td><td>0.182935</td><td>1547</td></tr><tr><td>&quot;Riya&quot;</td><td>0.096253</td><td>1548</td></tr><tr><td>&quot;Shiv&quot;</td><td>0.100765</td><td>1568</td></tr><tr><td>&quot;Ritvik&quot;</td><td>0.228446</td><td>1589</td></tr><tr><td>&quot;Tushar&quot;</td><td>0.133459</td><td>1596</td></tr><tr><td>&quot;Vani&quot;</td><td>0.168377</td><td>1657</td></tr><tr><td>&quot;Raghavendra&quot;</td><td>0.084177</td><td>1877</td></tr><tr><td>&quot;Anvi&quot;</td><td>0.179853</td><td>2035</td></tr><tr><td>&quot;Aaradhya&quot;</td><td>0.194621</td><td>2045</td></tr><tr><td>&quot;Rupak&quot;</td><td>0.162224</td><td>2176</td></tr><tr><td>&quot;Aarav&quot;</td><td>0.229024</td><td>2336</td></tr><tr><td>&quot;Rohan&quot;</td><td>0.140025</td><td>3178</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 3)\n",
       "┌─────────────┬────────────┬──────┐\n",
       "│ Name        ┆ Depression ┆ id   │\n",
       "│ ---         ┆ ---        ┆ ---  │\n",
       "│ str         ┆ f64        ┆ u32  │\n",
       "╞═════════════╪════════════╪══════╡\n",
       "│ Sanya       ┆ 0.147013   ┆ 1272 │\n",
       "│ Anushka     ┆ 0.213448   ┆ 1279 │\n",
       "│ Ritika      ┆ 0.126428   ┆ 1313 │\n",
       "│ Vidya       ┆ 0.200284   ┆ 1408 │\n",
       "│ Ansh        ┆ 0.152495   ┆ 1423 │\n",
       "│ Ishaani     ┆ 0.144888   ┆ 1477 │\n",
       "│ Anand       ┆ 0.312248   ┆ 1486 │\n",
       "│ Raunak      ┆ 0.185039   ┆ 1524 │\n",
       "│ Rashi       ┆ 0.182935   ┆ 1547 │\n",
       "│ Riya        ┆ 0.096253   ┆ 1548 │\n",
       "│ Shiv        ┆ 0.100765   ┆ 1568 │\n",
       "│ Ritvik      ┆ 0.228446   ┆ 1589 │\n",
       "│ Tushar      ┆ 0.133459   ┆ 1596 │\n",
       "│ Vani        ┆ 0.168377   ┆ 1657 │\n",
       "│ Raghavendra ┆ 0.084177   ┆ 1877 │\n",
       "│ Anvi        ┆ 0.179853   ┆ 2035 │\n",
       "│ Aaradhya    ┆ 0.194621   ┆ 2045 │\n",
       "│ Rupak       ┆ 0.162224   ┆ 2176 │\n",
       "│ Aarav       ┆ 0.229024   ┆ 2336 │\n",
       "│ Rohan       ┆ 0.140025   ┆ 3178 │\n",
       "└─────────────┴────────────┴──────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Gender</th><th>Depression</th><th>id</th></tr><tr><td>str</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Female&quot;</td><td>0.178237</td><td>63236</td></tr><tr><td>&quot;Male&quot;</td><td>0.18455</td><td>77464</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌────────┬────────────┬───────┐\n",
       "│ Gender ┆ Depression ┆ id    │\n",
       "│ ---    ┆ ---        ┆ ---   │\n",
       "│ str    ┆ f64        ┆ u32   │\n",
       "╞════════╪════════════╪═══════╡\n",
       "│ Female ┆ 0.178237   ┆ 63236 │\n",
       "│ Male   ┆ 0.18455    ┆ 77464 │\n",
       "└────────┴────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>City</th><th>Depression</th><th>id</th></tr><tr><td>str</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Jaipur&quot;</td><td>0.181377</td><td>4328</td></tr><tr><td>&quot;Kanpur&quot;</td><td>0.125739</td><td>4398</td></tr><tr><td>&quot;Hyderabad&quot;</td><td>0.275133</td><td>4496</td></tr><tr><td>&quot;Vadodara&quot;</td><td>0.167688</td><td>4568</td></tr><tr><td>&quot;Varanasi&quot;</td><td>0.142206</td><td>4606</td></tr><tr><td>&quot;Surat&quot;</td><td>0.201898</td><td>4636</td></tr><tr><td>&quot;Agra&quot;</td><td>0.192357</td><td>4684</td></tr><tr><td>&quot;Indore&quot;</td><td>0.16092</td><td>4872</td></tr><tr><td>&quot;Mumbai&quot;</td><td>0.131293</td><td>4966</td></tr><tr><td>&quot;Srinagar&quot;</td><td>0.211667</td><td>5074</td></tr><tr><td>&quot;Visakhapatnam&quot;</td><td>0.159196</td><td>5176</td></tr><tr><td>&quot;Rajkot&quot;</td><td>0.173228</td><td>5207</td></tr><tr><td>&quot;Pune&quot;</td><td>0.161036</td><td>5210</td></tr><tr><td>&quot;Ludhiana&quot;</td><td>0.19269</td><td>5226</td></tr><tr><td>&quot;Meerut&quot;</td><td>0.134045</td><td>5528</td></tr><tr><td>&quot;Ahmedabad&quot;</td><td>0.217887</td><td>5613</td></tr><tr><td>&quot;Kolkata&quot;</td><td>0.173668</td><td>5689</td></tr><tr><td>&quot;Vasai-Virar&quot;</td><td>0.197918</td><td>5765</td></tr><tr><td>&quot;Patna&quot;</td><td>0.163234</td><td>5924</td></tr><tr><td>&quot;Kalyan&quot;</td><td>0.199666</td><td>6591</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 3)\n",
       "┌───────────────┬────────────┬──────┐\n",
       "│ City          ┆ Depression ┆ id   │\n",
       "│ ---           ┆ ---        ┆ ---  │\n",
       "│ str           ┆ f64        ┆ u32  │\n",
       "╞═══════════════╪════════════╪══════╡\n",
       "│ Jaipur        ┆ 0.181377   ┆ 4328 │\n",
       "│ Kanpur        ┆ 0.125739   ┆ 4398 │\n",
       "│ Hyderabad     ┆ 0.275133   ┆ 4496 │\n",
       "│ Vadodara      ┆ 0.167688   ┆ 4568 │\n",
       "│ Varanasi      ┆ 0.142206   ┆ 4606 │\n",
       "│ Surat         ┆ 0.201898   ┆ 4636 │\n",
       "│ Agra          ┆ 0.192357   ┆ 4684 │\n",
       "│ Indore        ┆ 0.16092    ┆ 4872 │\n",
       "│ Mumbai        ┆ 0.131293   ┆ 4966 │\n",
       "│ Srinagar      ┆ 0.211667   ┆ 5074 │\n",
       "│ Visakhapatnam ┆ 0.159196   ┆ 5176 │\n",
       "│ Rajkot        ┆ 0.173228   ┆ 5207 │\n",
       "│ Pune          ┆ 0.161036   ┆ 5210 │\n",
       "│ Ludhiana      ┆ 0.19269    ┆ 5226 │\n",
       "│ Meerut        ┆ 0.134045   ┆ 5528 │\n",
       "│ Ahmedabad     ┆ 0.217887   ┆ 5613 │\n",
       "│ Kolkata       ┆ 0.173668   ┆ 5689 │\n",
       "│ Vasai-Virar   ┆ 0.197918   ┆ 5765 │\n",
       "│ Patna         ┆ 0.163234   ┆ 5924 │\n",
       "│ Kalyan        ┆ 0.199666   ┆ 6591 │\n",
       "└───────────────┴────────────┴──────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Profession</th><th>Depression</th><th>id</th></tr><tr><td>str</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Travel Consultant&quot;</td><td>0.046237</td><td>1860</td></tr><tr><td>&quot;Pilot&quot;</td><td>0.051228</td><td>1913</td></tr><tr><td>&quot;Marketing Manager&quot;</td><td>0.050607</td><td>1976</td></tr><tr><td>&quot;Customer Support&quot;</td><td>0.045255</td><td>2055</td></tr><tr><td>&quot;Lawyer&quot;</td><td>0.075045</td><td>2212</td></tr><tr><td>&quot;Researcher&quot;</td><td>0.040378</td><td>2328</td></tr><tr><td>&quot;Data Scientist&quot;</td><td>0.077824</td><td>2390</td></tr><tr><td>&quot;Educational Consultant&quot;</td><td>0.074684</td><td>2852</td></tr><tr><td>&quot;Chef&quot;</td><td>0.048567</td><td>2862</td></tr><tr><td>&quot;Chemist&quot;</td><td>0.028311</td><td>2967</td></tr><tr><td>&quot;Entrepreneur&quot;</td><td>0.020889</td><td>2968</td></tr><tr><td>&quot;Business Analyst&quot;</td><td>0.056628</td><td>3161</td></tr><tr><td>&quot;Doctor&quot;</td><td>0.052842</td><td>3255</td></tr><tr><td>&quot;Pharmacist&quot;</td><td>0.026715</td><td>3893</td></tr><tr><td>&quot;HR Manager&quot;</td><td>0.106912</td><td>4022</td></tr><tr><td>&quot;Consultant&quot;</td><td>0.047056</td><td>4229</td></tr><tr><td>&quot;Architect&quot;</td><td>0.099085</td><td>4370</td></tr><tr><td>&quot;Content Writer&quot;</td><td>0.018684</td><td>7814</td></tr><tr><td>&quot;Teacher&quot;</td><td>0.055649</td><td>24906</td></tr><tr><td>null</td><td>0.534944</td><td>36630</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 3)\n",
       "┌────────────────────────┬────────────┬───────┐\n",
       "│ Profession             ┆ Depression ┆ id    │\n",
       "│ ---                    ┆ ---        ┆ ---   │\n",
       "│ str                    ┆ f64        ┆ u32   │\n",
       "╞════════════════════════╪════════════╪═══════╡\n",
       "│ Travel Consultant      ┆ 0.046237   ┆ 1860  │\n",
       "│ Pilot                  ┆ 0.051228   ┆ 1913  │\n",
       "│ Marketing Manager      ┆ 0.050607   ┆ 1976  │\n",
       "│ Customer Support       ┆ 0.045255   ┆ 2055  │\n",
       "│ Lawyer                 ┆ 0.075045   ┆ 2212  │\n",
       "│ Researcher             ┆ 0.040378   ┆ 2328  │\n",
       "│ Data Scientist         ┆ 0.077824   ┆ 2390  │\n",
       "│ Educational Consultant ┆ 0.074684   ┆ 2852  │\n",
       "│ Chef                   ┆ 0.048567   ┆ 2862  │\n",
       "│ Chemist                ┆ 0.028311   ┆ 2967  │\n",
       "│ Entrepreneur           ┆ 0.020889   ┆ 2968  │\n",
       "│ Business Analyst       ┆ 0.056628   ┆ 3161  │\n",
       "│ Doctor                 ┆ 0.052842   ┆ 3255  │\n",
       "│ Pharmacist             ┆ 0.026715   ┆ 3893  │\n",
       "│ HR Manager             ┆ 0.106912   ┆ 4022  │\n",
       "│ Consultant             ┆ 0.047056   ┆ 4229  │\n",
       "│ Architect              ┆ 0.099085   ┆ 4370  │\n",
       "│ Content Writer         ┆ 0.018684   ┆ 7814  │\n",
       "│ Teacher                ┆ 0.055649   ┆ 24906 │\n",
       "│ null                   ┆ 0.534944   ┆ 36630 │\n",
       "└────────────────────────┴────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Sleep Duration</th><th>Depression</th><th>id</th></tr><tr><td>str</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;40-45 hours&quot;</td><td>1.0</td><td>1</td></tr><tr><td>&quot;49 hours&quot;</td><td>0.0</td><td>1</td></tr><tr><td>&quot;8-9 hours&quot;</td><td>0.5</td><td>2</td></tr><tr><td>&quot;10-11 hours&quot;</td><td>1.0</td><td>2</td></tr><tr><td>&quot;Sleep_Duration&quot;</td><td>0.0</td><td>2</td></tr><tr><td>&quot;Unhealthy&quot;</td><td>0.0</td><td>2</td></tr><tr><td>&quot;9-11 hours&quot;</td><td>0.0</td><td>2</td></tr><tr><td>&quot;45&quot;</td><td>0.0</td><td>2</td></tr><tr><td>&quot;1-6 hours&quot;</td><td>0.0</td><td>4</td></tr><tr><td>&quot;No&quot;</td><td>0.0</td><td>4</td></tr><tr><td>&quot;6-8 hours&quot;</td><td>0.0</td><td>4</td></tr><tr><td>&quot;2-3 hours&quot;</td><td>0.2</td><td>5</td></tr><tr><td>&quot;4-6 hours&quot;</td><td>0.2</td><td>5</td></tr><tr><td>&quot;4-5 hours&quot;</td><td>0.142857</td><td>7</td></tr><tr><td>&quot;6-7 hours&quot;</td><td>0.25</td><td>8</td></tr><tr><td>&quot;3-4 hours&quot;</td><td>0.083333</td><td>12</td></tr><tr><td>&quot;5-6 hours&quot;</td><td>0.165578</td><td>32142</td></tr><tr><td>&quot;More than 8 hours&quot;</td><td>0.138697</td><td>32726</td></tr><tr><td>&quot;7-8 hours&quot;</td><td>0.178339</td><td>36969</td></tr><tr><td>&quot;Less than 5 hours&quot;</td><td>0.234659</td><td>38784</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 3)\n",
       "┌───────────────────┬────────────┬───────┐\n",
       "│ Sleep Duration    ┆ Depression ┆ id    │\n",
       "│ ---               ┆ ---        ┆ ---   │\n",
       "│ str               ┆ f64        ┆ u32   │\n",
       "╞═══════════════════╪════════════╪═══════╡\n",
       "│ 40-45 hours       ┆ 1.0        ┆ 1     │\n",
       "│ 49 hours          ┆ 0.0        ┆ 1     │\n",
       "│ 8-9 hours         ┆ 0.5        ┆ 2     │\n",
       "│ 10-11 hours       ┆ 1.0        ┆ 2     │\n",
       "│ Sleep_Duration    ┆ 0.0        ┆ 2     │\n",
       "│ Unhealthy         ┆ 0.0        ┆ 2     │\n",
       "│ 9-11 hours        ┆ 0.0        ┆ 2     │\n",
       "│ 45                ┆ 0.0        ┆ 2     │\n",
       "│ 1-6 hours         ┆ 0.0        ┆ 4     │\n",
       "│ No                ┆ 0.0        ┆ 4     │\n",
       "│ 6-8 hours         ┆ 0.0        ┆ 4     │\n",
       "│ 2-3 hours         ┆ 0.2        ┆ 5     │\n",
       "│ 4-6 hours         ┆ 0.2        ┆ 5     │\n",
       "│ 4-5 hours         ┆ 0.142857   ┆ 7     │\n",
       "│ 6-7 hours         ┆ 0.25       ┆ 8     │\n",
       "│ 3-4 hours         ┆ 0.083333   ┆ 12    │\n",
       "│ 5-6 hours         ┆ 0.165578   ┆ 32142 │\n",
       "│ More than 8 hours ┆ 0.138697   ┆ 32726 │\n",
       "│ 7-8 hours         ┆ 0.178339   ┆ 36969 │\n",
       "│ Less than 5 hours ┆ 0.234659   ┆ 38784 │\n",
       "└───────────────────┴────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Dietary Habits</th><th>Depression</th><th>id</th></tr><tr><td>str</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Vegas&quot;</td><td>0.0</td><td>1</td></tr><tr><td>&quot;3&quot;</td><td>1.0</td><td>1</td></tr><tr><td>&quot;Indoor&quot;</td><td>1.0</td><td>1</td></tr><tr><td>&quot;Less than Healthy&quot;</td><td>0.0</td><td>1</td></tr><tr><td>&quot;1.0&quot;</td><td>1.0</td><td>1</td></tr><tr><td>&quot;Gender&quot;</td><td>0.0</td><td>1</td></tr><tr><td>&quot;Class 12&quot;</td><td>0.0</td><td>1</td></tr><tr><td>&quot;Electrician&quot;</td><td>0.0</td><td>1</td></tr><tr><td>&quot;Hormonal&quot;</td><td>0.0</td><td>1</td></tr><tr><td>&quot;M.Tech&quot;</td><td>1.0</td><td>1</td></tr><tr><td>&quot;Mihir&quot;</td><td>0.0</td><td>1</td></tr><tr><td>&quot;2&quot;</td><td>0.0</td><td>1</td></tr><tr><td>&quot;BSc&quot;</td><td>0.0</td><td>1</td></tr><tr><td>&quot;No&quot;</td><td>0.0</td><td>2</td></tr><tr><td>&quot;Yes&quot;</td><td>0.5</td><td>2</td></tr><tr><td>&quot;More Healthy&quot;</td><td>0.0</td><td>2</td></tr><tr><td>null</td><td>0.5</td><td>4</td></tr><tr><td>&quot;Healthy&quot;</td><td>0.118035</td><td>44741</td></tr><tr><td>&quot;Unhealthy&quot;</td><td>0.26054</td><td>46227</td></tr><tr><td>&quot;Moderate&quot;</td><td>0.165637</td><td>49705</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 3)\n",
       "┌───────────────────┬────────────┬───────┐\n",
       "│ Dietary Habits    ┆ Depression ┆ id    │\n",
       "│ ---               ┆ ---        ┆ ---   │\n",
       "│ str               ┆ f64        ┆ u32   │\n",
       "╞═══════════════════╪════════════╪═══════╡\n",
       "│ Vegas             ┆ 0.0        ┆ 1     │\n",
       "│ 3                 ┆ 1.0        ┆ 1     │\n",
       "│ Indoor            ┆ 1.0        ┆ 1     │\n",
       "│ Less than Healthy ┆ 0.0        ┆ 1     │\n",
       "│ 1.0               ┆ 1.0        ┆ 1     │\n",
       "│ Gender            ┆ 0.0        ┆ 1     │\n",
       "│ Class 12          ┆ 0.0        ┆ 1     │\n",
       "│ Electrician       ┆ 0.0        ┆ 1     │\n",
       "│ Hormonal          ┆ 0.0        ┆ 1     │\n",
       "│ M.Tech            ┆ 1.0        ┆ 1     │\n",
       "│ Mihir             ┆ 0.0        ┆ 1     │\n",
       "│ 2                 ┆ 0.0        ┆ 1     │\n",
       "│ BSc               ┆ 0.0        ┆ 1     │\n",
       "│ No                ┆ 0.0        ┆ 2     │\n",
       "│ Yes               ┆ 0.5        ┆ 2     │\n",
       "│ More Healthy      ┆ 0.0        ┆ 2     │\n",
       "│ null              ┆ 0.5        ┆ 4     │\n",
       "│ Healthy           ┆ 0.118035   ┆ 44741 │\n",
       "│ Unhealthy         ┆ 0.26054    ┆ 46227 │\n",
       "│ Moderate          ┆ 0.165637   ┆ 49705 │\n",
       "└───────────────────┴────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Degree</th><th>Depression</th><th>id</th></tr><tr><td>str</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;ME&quot;</td><td>0.071861</td><td>3632</td></tr><tr><td>&quot;BA&quot;</td><td>0.125867</td><td>3750</td></tr><tr><td>&quot;MBA&quot;</td><td>0.12022</td><td>3818</td></tr><tr><td>&quot;BHM&quot;</td><td>0.17259</td><td>4305</td></tr><tr><td>&quot;LLB&quot;</td><td>0.150644</td><td>4348</td></tr><tr><td>&quot;B.Tech&quot;</td><td>0.214011</td><td>4425</td></tr><tr><td>&quot;M.Tech&quot;</td><td>0.144581</td><td>4475</td></tr><tr><td>&quot;M.Pharm&quot;</td><td>0.098082</td><td>4537</td></tr><tr><td>&quot;LLM&quot;</td><td>0.114052</td><td>4647</td></tr><tr><td>&quot;MSc&quot;</td><td>0.174011</td><td>4879</td></tr><tr><td>&quot;BSc&quot;</td><td>0.15556</td><td>5027</td></tr><tr><td>&quot;BBA&quot;</td><td>0.134394</td><td>5030</td></tr><tr><td>&quot;MCA&quot;</td><td>0.146733</td><td>5234</td></tr><tr><td>&quot;M.Ed&quot;</td><td>0.097212</td><td>5668</td></tr><tr><td>&quot;BCA&quot;</td><td>0.203868</td><td>5739</td></tr><tr><td>&quot;B.Pharm&quot;</td><td>0.119194</td><td>5856</td></tr><tr><td>&quot;B.Com&quot;</td><td>0.155676</td><td>8113</td></tr><tr><td>&quot;B.Arch&quot;</td><td>0.157515</td><td>8742</td></tr><tr><td>&quot;B.Ed&quot;</td><td>0.128732</td><td>11691</td></tr><tr><td>&quot;Class 12&quot;</td><td>0.512526</td><td>14729</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 3)\n",
       "┌──────────┬────────────┬───────┐\n",
       "│ Degree   ┆ Depression ┆ id    │\n",
       "│ ---      ┆ ---        ┆ ---   │\n",
       "│ str      ┆ f64        ┆ u32   │\n",
       "╞══════════╪════════════╪═══════╡\n",
       "│ ME       ┆ 0.071861   ┆ 3632  │\n",
       "│ BA       ┆ 0.125867   ┆ 3750  │\n",
       "│ MBA      ┆ 0.12022    ┆ 3818  │\n",
       "│ BHM      ┆ 0.17259    ┆ 4305  │\n",
       "│ LLB      ┆ 0.150644   ┆ 4348  │\n",
       "│ B.Tech   ┆ 0.214011   ┆ 4425  │\n",
       "│ M.Tech   ┆ 0.144581   ┆ 4475  │\n",
       "│ M.Pharm  ┆ 0.098082   ┆ 4537  │\n",
       "│ LLM      ┆ 0.114052   ┆ 4647  │\n",
       "│ MSc      ┆ 0.174011   ┆ 4879  │\n",
       "│ BSc      ┆ 0.15556    ┆ 5027  │\n",
       "│ BBA      ┆ 0.134394   ┆ 5030  │\n",
       "│ MCA      ┆ 0.146733   ┆ 5234  │\n",
       "│ M.Ed     ┆ 0.097212   ┆ 5668  │\n",
       "│ BCA      ┆ 0.203868   ┆ 5739  │\n",
       "│ B.Pharm  ┆ 0.119194   ┆ 5856  │\n",
       "│ B.Com    ┆ 0.155676   ┆ 8113  │\n",
       "│ B.Arch   ┆ 0.157515   ┆ 8742  │\n",
       "│ B.Ed     ┆ 0.128732   ┆ 11691 │\n",
       "│ Class 12 ┆ 0.512526   ┆ 14729 │\n",
       "└──────────┴────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Have you ever had suicidal thoughts ?</th><th>Depression</th><th>id</th></tr><tr><td>str</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Yes&quot;</td><td>0.317832</td><td>69562</td></tr><tr><td>&quot;No&quot;</td><td>0.04861</td><td>71138</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌─────────────────────────────────┬────────────┬───────┐\n",
       "│ Have you ever had suicidal tho… ┆ Depression ┆ id    │\n",
       "│ ---                             ┆ ---        ┆ ---   │\n",
       "│ str                             ┆ f64        ┆ u32   │\n",
       "╞═════════════════════════════════╪════════════╪═══════╡\n",
       "│ Yes                             ┆ 0.317832   ┆ 69562 │\n",
       "│ No                              ┆ 0.04861    ┆ 71138 │\n",
       "└─────────────────────────────────┴────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Family History of Mental Illness</th><th>Depression</th><th>id</th></tr><tr><td>str</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Yes&quot;</td><td>0.188113</td><td>69942</td></tr><tr><td>&quot;No&quot;</td><td>0.175387</td><td>70758</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌─────────────────────────────────┬────────────┬───────┐\n",
       "│ Family History of Mental Illne… ┆ Depression ┆ id    │\n",
       "│ ---                             ┆ ---        ┆ ---   │\n",
       "│ str                             ┆ f64        ┆ u32   │\n",
       "╞═════════════════════════════════╪════════════╪═══════╡\n",
       "│ Yes                             ┆ 0.188113   ┆ 69942 │\n",
       "│ No                              ┆ 0.175387   ┆ 70758 │\n",
       "└─────────────────────────────────┴────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_features = ['Name', 'Gender', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', 'Degree', \n",
    "               'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
    "\n",
    "for feature in cat_features :\n",
    "   display (train_df.group_by(feature).agg(pl.col('Depression').mean(), pl.col('id').len()).sort( by = \"id\").tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a226f0b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:26.290718Z",
     "iopub.status.busy": "2024-11-09T18:37:26.289974Z",
     "iopub.status.idle": "2024-11-09T18:37:26.306617Z",
     "shell.execute_reply": "2024-11-09T18:37:26.305559Z"
    },
    "papermill": {
     "duration": 0.032066,
     "end_time": "2024-11-09T18:37:26.309216",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.277150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>by</th><th>Depression</th><th>id</th></tr><tr><td>str</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Working Professional&quot;</td><td>0.081836</td><td>112799</td></tr><tr><td>&quot;Student&quot;</td><td>0.585499</td><td>27901</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌──────────────────────┬────────────┬────────┐\n",
       "│ by                   ┆ Depression ┆ id     │\n",
       "│ ---                  ┆ ---        ┆ ---    │\n",
       "│ str                  ┆ f64        ┆ u32    │\n",
       "╞══════════════════════╪════════════╪════════╡\n",
       "│ Working Professional ┆ 0.081836   ┆ 112799 │\n",
       "│ Student              ┆ 0.585499   ┆ 27901  │\n",
       "└──────────────────────┴────────────┴────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.group_by (by = 'Working Professional or Student').agg(pl.col('Depression').mean(), pl.col('id').len())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12764592",
   "metadata": {
    "papermill": {
     "duration": 0.011552,
     "end_time": "2024-11-09T18:37:26.332497",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.320945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b11eaa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:26.358485Z",
     "iopub.status.busy": "2024-11-09T18:37:26.357337Z",
     "iopub.status.idle": "2024-11-09T18:37:26.363275Z",
     "shell.execute_reply": "2024-11-09T18:37:26.362154Z"
    },
    "papermill": {
     "duration": 0.021392,
     "end_time": "2024-11-09T18:37:26.365690",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.344298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop entries in the original dataset without a target \n",
    "# only needed if the original dataset is included \n",
    "# dep = ['0','1']\n",
    "# original_df = original_df.filter (pl.col('Depression').is_in (dep))\n",
    "# original_df_id = original_df.with_row_index ( 'id', offset = 60000)\n",
    "# original_df_id = original_df_id.with_columns  (pl.lit (2).alias ('importance'))\n",
    "# train_df = train_df.with_columns  (pl.lit (1).alias ('importance'))\n",
    "\n",
    "# print (f'train shape : {train_df.shape}')\n",
    "# print (f'orig shape : {original_df_id.shape}')\n",
    "# train_orig_df = pl.concat ([train_df, original_df_id], how = 'vertical_relaxed')\n",
    "# train_orig_df = train_orig_df.with_columns(pl.col('Depression').cast(pl.Int8))\n",
    "# display  (train_orig_df.collect_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04bdd6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:26.391364Z",
     "iopub.status.busy": "2024-11-09T18:37:26.390658Z",
     "iopub.status.idle": "2024-11-09T18:37:26.395348Z",
     "shell.execute_reply": "2024-11-09T18:37:26.394277Z"
    },
    "papermill": {
     "duration": 0.020056,
     "end_time": "2024-11-09T18:37:26.397691",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.377635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def clean_column (df : pl.DataFrame, feature: str, range : list) -> pl.DataFrame :\n",
    "\n",
    "#     return df.with_columns (pl.when (pl.col(feature).is_in (range)).then (pl.col(feature)).otherwise(pl.lit ('other')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2150cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:26.423716Z",
     "iopub.status.busy": "2024-11-09T18:37:26.422657Z",
     "iopub.status.idle": "2024-11-09T18:37:26.428100Z",
     "shell.execute_reply": "2024-11-09T18:37:26.427050Z"
    },
    "papermill": {
     "duration": 0.02092,
     "end_time": "2024-11-09T18:37:26.430434",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.409514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_orig_df = train_orig_df.pipe (\n",
    "#                 clean_column, feature = 'Sleep Duration', range = [\"Less than 5 hours\",\"5-6 hours\", \n",
    "#                                                  \"6-7 hours\", \"7-8 hours\",\"More than 8 hours\"]).pipe(\n",
    "#                 clean_column, feature = 'Dietary Habits', range = [\"Healthy\", \"Moderate\", \"Unhealthy\"\t])\n",
    "\n",
    "# test_df = test_df.pipe(\n",
    "#                 clean_column, feature = 'Sleep Duration', range = [\"Less than 5 hours\",\"5-6 hours\", \n",
    "#                                                  \"6-7 hours\", \"7-8 hours\",\"More than 8 hours\"]).pipe(\n",
    "#                 clean_column, feature = 'Dietary Habits', range = [\"Healthy\", \"Moderate\", \"Unhealthy\"\t])\n",
    "\n",
    "\n",
    "# train_orig_df.group_by (by = 'Sleep Duration').len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d18f72",
   "metadata": {
    "papermill": {
     "duration": 0.011293,
     "end_time": "2024-11-09T18:37:26.453454",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.442161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Control size for testing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bba6fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:26.479377Z",
     "iopub.status.busy": "2024-11-09T18:37:26.478379Z",
     "iopub.status.idle": "2024-11-09T18:37:26.483280Z",
     "shell.execute_reply": "2024-11-09T18:37:26.482266Z"
    },
    "papermill": {
     "duration": 0.020506,
     "end_time": "2024-11-09T18:37:26.485727",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.465221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train_orig_df = train_orig_df.sample( fraction = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6ffa2",
   "metadata": {
    "papermill": {
     "duration": 0.011441,
     "end_time": "2024-11-09T18:37:26.508858",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.497417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Seperating the data into two groups (professional/student)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "566ee27c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:26.534314Z",
     "iopub.status.busy": "2024-11-09T18:37:26.533543Z",
     "iopub.status.idle": "2024-11-09T18:37:26.574791Z",
     "shell.execute_reply": "2024-11-09T18:37:26.573692Z"
    },
    "papermill": {
     "duration": 0.05679,
     "end_time": "2024-11-09T18:37:26.577369",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.520579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "students : 27901 professionals : 112799\n"
     ]
    }
   ],
   "source": [
    "def seperate_students (df): \n",
    "\n",
    "    df_student = df.filter (pl.col('Working Professional or Student') == 'Student')\n",
    "    df_professional = df.filter (pl.col('Working Professional or Student') != 'Student')\n",
    "\n",
    "    print (f\"students : {df_student.shape[0]} professionals : {df_professional.shape[0]}\")\n",
    "    student_id = df_student.select ('id')\n",
    "    df_student = df_student.drop([ 'id', \n",
    "    #                               'Name',\n",
    "                                    'Working Professional or Student', \n",
    "                                    'Profession', \n",
    "                                    'Work Pressure', \n",
    "                                    'Job Satisfaction'])\n",
    "    professional_id = df_professional.select ('id')\n",
    "    df_professional = df_professional .drop (['id',\n",
    "    #                                          'Name', \n",
    "                                               'Working Professional or Student', \n",
    "                                               'Academic Pressure', \n",
    "                                               'CGPA', \n",
    "                                               'Study Satisfaction']) \n",
    "    return df_student, student_id, df_professional, professional_id\n",
    "\n",
    "train_df_student, train_student_id, train_df_professional, train_professional_id = seperate_students (train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05bc8acc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:26.603323Z",
     "iopub.status.busy": "2024-11-09T18:37:26.602549Z",
     "iopub.status.idle": "2024-11-09T18:37:26.640454Z",
     "shell.execute_reply": "2024-11-09T18:37:26.639368Z"
    },
    "papermill": {
     "duration": 0.053654,
     "end_time": "2024-11-09T18:37:26.642990",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.589336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>Age</th><th>Academic Pressure</th><th>CGPA</th><th>Study Satisfaction</th><th>Work/Study Hours</th><th>Financial Stress</th><th>Depression</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>27901.0</td><td>27892.0</td><td>27892.0</td><td>27891.0</td><td>27901.0</td><td>27898.0</td><td>27901.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>9.0</td><td>9.0</td><td>10.0</td><td>0.0</td><td>3.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>25.8223</td><td>3.142227</td><td>7.658575</td><td>2.944893</td><td>7.156984</td><td>3.139867</td><td>0.585499</td></tr><tr><td>&quot;std&quot;</td><td>4.905687</td><td>1.380535</td><td>1.464499</td><td>1.36025</td><td>3.707642</td><td>1.437347</td><td>0.492645</td></tr><tr><td>&quot;min&quot;</td><td>18.0</td><td>1.0</td><td>5.03</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>21.0</td><td>2.0</td><td>6.29</td><td>2.0</td><td>4.0</td><td>2.0</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>25.0</td><td>3.0</td><td>7.77</td><td>3.0</td><td>8.0</td><td>3.0</td><td>1.0</td></tr><tr><td>&quot;75%&quot;</td><td>30.0</td><td>4.0</td><td>8.92</td><td>4.0</td><td>10.0</td><td>4.0</td><td>1.0</td></tr><tr><td>&quot;max&quot;</td><td>59.0</td><td>5.0</td><td>10.0</td><td>5.0</td><td>12.0</td><td>5.0</td><td>1.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 8)\n",
       "┌────────────┬──────────┬────────────┬──────────┬────────────┬────────────┬────────────┬───────────┐\n",
       "│ statistic  ┆ Age      ┆ Academic   ┆ CGPA     ┆ Study Sati ┆ Work/Study ┆ Financial  ┆ Depressio │\n",
       "│ ---        ┆ ---      ┆ Pressure   ┆ ---      ┆ sfaction   ┆ Hours      ┆ Stress     ┆ n         │\n",
       "│ str        ┆ f64      ┆ ---        ┆ f64      ┆ ---        ┆ ---        ┆ ---        ┆ ---       │\n",
       "│            ┆          ┆ f64        ┆          ┆ f64        ┆ f64        ┆ f64        ┆ f64       │\n",
       "╞════════════╪══════════╪════════════╪══════════╪════════════╪════════════╪════════════╪═══════════╡\n",
       "│ count      ┆ 27901.0  ┆ 27892.0    ┆ 27892.0  ┆ 27891.0    ┆ 27901.0    ┆ 27898.0    ┆ 27901.0   │\n",
       "│ null_count ┆ 0.0      ┆ 9.0        ┆ 9.0      ┆ 10.0       ┆ 0.0        ┆ 3.0        ┆ 0.0       │\n",
       "│ mean       ┆ 25.8223  ┆ 3.142227   ┆ 7.658575 ┆ 2.944893   ┆ 7.156984   ┆ 3.139867   ┆ 0.585499  │\n",
       "│ std        ┆ 4.905687 ┆ 1.380535   ┆ 1.464499 ┆ 1.36025    ┆ 3.707642   ┆ 1.437347   ┆ 0.492645  │\n",
       "│ min        ┆ 18.0     ┆ 1.0        ┆ 5.03     ┆ 1.0        ┆ 0.0        ┆ 1.0        ┆ 0.0       │\n",
       "│ 25%        ┆ 21.0     ┆ 2.0        ┆ 6.29     ┆ 2.0        ┆ 4.0        ┆ 2.0        ┆ 0.0       │\n",
       "│ 50%        ┆ 25.0     ┆ 3.0        ┆ 7.77     ┆ 3.0        ┆ 8.0        ┆ 3.0        ┆ 1.0       │\n",
       "│ 75%        ┆ 30.0     ┆ 4.0        ┆ 8.92     ┆ 4.0        ┆ 10.0       ┆ 4.0        ┆ 1.0       │\n",
       "│ max        ┆ 59.0     ┆ 5.0        ┆ 10.0     ┆ 5.0        ┆ 12.0       ┆ 5.0        ┆ 1.0       │\n",
       "└────────────┴──────────┴────────────┴──────────┴────────────┴────────────┴────────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>Age</th><th>Work Pressure</th><th>Job Satisfaction</th><th>Work/Study Hours</th><th>Financial Stress</th><th>Depression</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>112799.0</td><td>112779.0</td><td>112782.0</td><td>112799.0</td><td>112798.0</td><td>112799.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>20.0</td><td>17.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>43.991622</td><td>2.998971</td><td>2.974446</td><td>6.028998</td><td>2.951666</td><td>0.081836</td></tr><tr><td>&quot;std&quot;</td><td>10.94917</td><td>1.405761</td><td>1.416088</td><td>3.856315</td><td>1.405216</td><td>0.274116</td></tr><tr><td>&quot;min&quot;</td><td>18.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>38.0</td><td>2.0</td><td>2.0</td><td>3.0</td><td>2.0</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>46.0</td><td>3.0</td><td>3.0</td><td>6.0</td><td>3.0</td><td>0.0</td></tr><tr><td>&quot;75%&quot;</td><td>53.0</td><td>4.0</td><td>4.0</td><td>9.0</td><td>4.0</td><td>0.0</td></tr><tr><td>&quot;max&quot;</td><td>60.0</td><td>5.0</td><td>5.0</td><td>12.0</td><td>5.0</td><td>1.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 7)\n",
       "┌────────────┬───────────┬──────────┬──────────────────┬────────────┬───────────┬────────────┐\n",
       "│ statistic  ┆ Age       ┆ Work     ┆ Job Satisfaction ┆ Work/Study ┆ Financial ┆ Depression │\n",
       "│ ---        ┆ ---       ┆ Pressure ┆ ---              ┆ Hours      ┆ Stress    ┆ ---        │\n",
       "│ str        ┆ f64       ┆ ---      ┆ f64              ┆ ---        ┆ ---       ┆ f64        │\n",
       "│            ┆           ┆ f64      ┆                  ┆ f64        ┆ f64       ┆            │\n",
       "╞════════════╪═══════════╪══════════╪══════════════════╪════════════╪═══════════╪════════════╡\n",
       "│ count      ┆ 112799.0  ┆ 112779.0 ┆ 112782.0         ┆ 112799.0   ┆ 112798.0  ┆ 112799.0   │\n",
       "│ null_count ┆ 0.0       ┆ 20.0     ┆ 17.0             ┆ 0.0        ┆ 1.0       ┆ 0.0        │\n",
       "│ mean       ┆ 43.991622 ┆ 2.998971 ┆ 2.974446         ┆ 6.028998   ┆ 2.951666  ┆ 0.081836   │\n",
       "│ std        ┆ 10.94917  ┆ 1.405761 ┆ 1.416088         ┆ 3.856315   ┆ 1.405216  ┆ 0.274116   │\n",
       "│ min        ┆ 18.0      ┆ 1.0      ┆ 1.0              ┆ 0.0        ┆ 1.0       ┆ 0.0        │\n",
       "│ 25%        ┆ 38.0      ┆ 2.0      ┆ 2.0              ┆ 3.0        ┆ 2.0       ┆ 0.0        │\n",
       "│ 50%        ┆ 46.0      ┆ 3.0      ┆ 3.0              ┆ 6.0        ┆ 3.0       ┆ 0.0        │\n",
       "│ 75%        ┆ 53.0      ┆ 4.0      ┆ 4.0              ┆ 9.0        ┆ 4.0       ┆ 0.0        │\n",
       "│ max        ┆ 60.0      ┆ 5.0      ┆ 5.0              ┆ 12.0       ┆ 5.0       ┆ 1.0        │\n",
       "└────────────┴───────────┴──────────┴──────────────────┴────────────┴───────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import polars.selectors as cs\n",
    "\n",
    "display (train_df_student.select (cs.numeric()).describe())\n",
    "display (train_df_professional.select (cs.numeric()).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a370f",
   "metadata": {
    "papermill": {
     "duration": 0.012076,
     "end_time": "2024-11-09T18:37:26.667429",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.655353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installing Autogluon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525a0512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:37:26.695112Z",
     "iopub.status.busy": "2024-11-09T18:37:26.694661Z",
     "iopub.status.idle": "2024-11-09T18:38:04.069829Z",
     "shell.execute_reply": "2024-11-09T18:38:04.068462Z"
    },
    "papermill": {
     "duration": 37.392945,
     "end_time": "2024-11-09T18:38:04.072777",
     "exception": false,
     "start_time": "2024-11-09T18:37:26.679832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.15.1 requires botocore<1.35.24,>=1.35.16, but you have botocore 1.29.165 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.3 which is incompatible.\r\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install autogluon.tabular --no-cache-dir -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d257e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:38:04.100280Z",
     "iopub.status.busy": "2024-11-09T18:38:04.099490Z",
     "iopub.status.idle": "2024-11-09T18:38:29.508055Z",
     "shell.execute_reply": "2024-11-09T18:38:29.506757Z"
    },
    "papermill": {
     "duration": 25.425634,
     "end_time": "2024-11-09T18:38:29.510893",
     "exception": false,
     "start_time": "2024-11-09T18:38:04.085259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ray==2.10.0\r\n",
      "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (8.1.7)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (3.15.1)\r\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (4.22.0)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (1.0.8)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (3.20.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (6.0.2)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (1.4.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (2.32.3)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.10.0) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.10.0) (2023.12.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.10.0) (0.35.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.10.0) (0.18.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray==2.10.0) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.10.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.10.0) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.10.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.10.0) (2024.8.30)\r\n",
      "Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: ray\r\n",
      "  Attempting uninstall: ray\r\n",
      "    Found existing installation: ray 2.24.0\r\n",
      "    Uninstalling ray-2.24.0:\r\n",
      "      Successfully uninstalled ray-2.24.0\r\n",
      "Successfully installed ray-2.10.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ray==2.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40061a6",
   "metadata": {
    "papermill": {
     "duration": 0.014732,
     "end_time": "2024-11-09T18:38:29.541015",
     "exception": false,
     "start_time": "2024-11-09T18:38:29.526283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training (seperate by student /professional) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef533fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T18:38:29.573849Z",
     "iopub.status.busy": "2024-11-09T18:38:29.572923Z",
     "iopub.status.idle": "2024-11-09T23:15:15.933222Z",
     "shell.execute_reply": "2024-11-09T23:15:15.931977Z"
    },
    "papermill": {
     "duration": 16606.380784,
     "end_time": "2024-11-09T23:15:15.937050",
     "exception": false,
     "start_time": "2024-11-09T18:38:29.556266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       30.20 GB / 31.36 GB (96.3%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 5250s of the 21000s of remaining time (25%).\n",
      "2024-11-09 18:38:32,985\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-11-09 18:38:35,874\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\t\tContext path: \"/kaggle/working/Autogluon/student_medium/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Beginning AutoGluon training ... Time limit = 5245s\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m AutoGluon will save models to \"/kaggle/working/Autogluon/student_medium/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Train Data Rows:    24800\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Train Data Columns: 14\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Label Column:       Depression\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tAvailable Memory:                    30503.96 MB\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tTrain Data (Original)  Memory Usage: 13.07 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\t('float', [])  : 6 | ['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', ...]\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\t('object', []) : 8 | ['Name', 'Gender', 'City', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\t('category', [])  : 5 | ['Name', 'City', 'Sleep Duration', 'Dietary Habits', 'Degree']\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\t('float', [])     : 6 | ['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', ...]\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t\t('int', ['bool']) : 3 | ['Gender', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.3s = Fit runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t14 features in original data used to generate 14 features in processed data.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tTrain Data (Processed) Memory Usage: 1.35 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting 110 L1 models ...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3495.37s of the 5244.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.8126\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3491.08s of the 5240.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.8058\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3490.8s of the 5239.78s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9204\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t25.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.7s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 3461.51s of the 5210.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9159\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t25.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3432.86s of the 5181.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.914\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t5.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3426.16s of the 5175.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9149\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t5.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 3419.04s of the 5168.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9233\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t135.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3280.01s of the 5028.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9144\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t3.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.2s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3274.88s of the 5023.86s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9149\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t3.29s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.2s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3269.76s of the 5018.74s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=1378)\u001b[0m No improvement since epoch 1: early stopping\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1378)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1378)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.919\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t100.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 3166.26s of the 4915.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9192\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t24.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.47s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3137.65s of the 4886.63s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=1465)\u001b[0m No improvement since epoch 1: early stopping\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1465)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1465)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1788)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=1788)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1786)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1917)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1917)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2001)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2001)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9181\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t99.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.42s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3034.79s of the 4783.77s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9151\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t36.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.93s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 2994.25s of the 4743.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9237\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t83.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 2907.15s of the 4656.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=2619)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2619)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=2620)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2620)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2775)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2775)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9192\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t116.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.45s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 2786.7s of the 4535.68s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=2746)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2746)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9172\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t54.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t6.39s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2727.62s of the 4476.6s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=2837)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2837)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=3130)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_ray_fit pid=3130)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3130)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=3132)\u001b[0m No improvement since epoch 13: early stopping\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3132)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3132)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3308)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_ray_fit pid=3308)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3308)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=3279)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_ray_fit pid=3279)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3279)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=3392)\u001b[0m No improvement since epoch 7: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3392)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3392)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9168\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t237.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.56s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 2486.38s of the 4235.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.921\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t93.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 2389.32s of the 4138.3s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3757)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.340667\n",
      "\u001b[36m(_ray_fit pid=3871)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.360394\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3955)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.347327\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9214\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t54.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t8.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 2330.47s of the 4079.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=4001)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4001)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=4000)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4000)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4127)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4127)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=4158)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4158)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=4155)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4155)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9165\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t144.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.56s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 2182.49s of the 3931.47s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=4225)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4225)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9183\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t58.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t3.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 2120.38s of the 3869.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9106\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t4.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 2113.81s of the 3862.78s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9236\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t184.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1925.83s of the 3674.81s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=4843)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_ray_fit pid=4843)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4843)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=4990)\u001b[0m No improvement since epoch 1: early stopping\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4990)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4990)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9152\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t43.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.53s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 1879.11s of the 3628.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9234\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t308.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.55s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 1566.86s of the 3315.84s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=5047)\u001b[0m No improvement since epoch 2: early stopping\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5047)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5047)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9088\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t10.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 1554.71s of the 3303.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9199\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t35.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t3.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 1515.49s of the 3264.47s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=5727)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_ray_fit pid=5727)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=5727)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=5729)\u001b[0m No improvement since epoch 3: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5729)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5729)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5730)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_ray_fit pid=5730)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=5730)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=5875)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_ray_fit pid=5875)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=5875)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=5988)\u001b[0m No improvement since epoch 2: early stopping\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5988)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5988)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9169\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t230.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.74s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 1280.53s of the 3029.5s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9211\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t27.22s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.51s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 1249.68s of the 2998.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=6282)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6282)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=6281)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6281)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6438)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6438)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=6409)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6409)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=6508)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6508)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9191\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t160.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.59s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 1085.01s of the 2833.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9174\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t28.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.97s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 1051.63s of the 2800.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=6798)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6798)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=6796)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6796)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=6797)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6797)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=6923)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6923)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7013)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=7013)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=6959)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6959)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9176\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t176.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.44s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 871.47s of the 2620.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9221\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t48.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 818.36s of the 2567.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=6957)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6957)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=7385)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_ray_fit pid=7385)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=7385)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=7382)\u001b[0m No improvement since epoch 2: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7382)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7382)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7530)\u001b[0m No improvement since epoch 0: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7530)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7530)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7635)\u001b[0m No improvement since epoch 0: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7635)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7635)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7607)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_ray_fit pid=7607)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=7607)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9126\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t307.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t2.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 507.35s of the 2256.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9099\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t15.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.4s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 487.77s of the 2236.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9139\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t5.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 481.05s of the 2230.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9234\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t147.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.27s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 329.77s of the 2078.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=8270)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_ray_fit pid=8270)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=8270)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=8417)\u001b[0m No improvement since epoch 0: early stopping\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8417)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8417)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9175\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t124.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.49s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 201.18s of the 1950.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=8580)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=8422)\u001b[0m No improvement since epoch 1: early stopping\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8580)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8422)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8707)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8707)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9196\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t57.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.34s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 140.02s of the 1889.0s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9181\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t86.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t20.82s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 45.87s of the 1794.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=8710)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8710)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=9092)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 20)\n",
      "\u001b[36m(_ray_fit pid=9092)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=9092)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=9089)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=9292)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 20)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=9292)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=9292)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9201\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t53.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1737.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tEnsemble Weights: {'CatBoost_r177_BAG_L1': 0.389, 'CatBoost_r137_BAG_L1': 0.222, 'CatBoost_r13_BAG_L1': 0.111, 'NeuralNetTorch_r79_BAG_L1': 0.056, 'NeuralNetFastAI_r191_BAG_L1': 0.056, 'LightGBM_r96_BAG_L1': 0.056, 'NeuralNetTorch_r86_BAG_L1': 0.056, 'NeuralNetFastAI_r143_BAG_L1': 0.056}\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9242\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t3.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting 108 L2 models ...\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1734.21s of the 1733.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9219\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t39.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.86s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 1690.21s of the 1689.99s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=9238)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 20)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=9238)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=9238)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9198\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t48.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.71s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 1637.52s of the 1637.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.92\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t25.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.47s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 1610.35s of the 1610.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9215\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t31.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.41s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 1576.92s of the 1576.7s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9238\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t103.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.21s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 1469.44s of the 1469.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9217\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t4.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.58s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 1462.46s of the 1462.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9217\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t4.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.59s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1455.4s of the 1455.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\u001b[36m(_ray_fit pid=10286)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_ray_fit pid=10286)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=10286)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=10431)\u001b[0m No improvement since epoch 1: early stopping\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10431)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10431)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9209\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t112.78s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.21s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 1338.69s of the 1338.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9227\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t30.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.42s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1303.94s of the 1303.71s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=10490)\u001b[0m No improvement since epoch 1: early stopping\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10490)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10490)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_ray_fit pid=10849)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=10849)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=10852)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=10850)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10850)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10981)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=10981)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=10979)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=10979)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=11064)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=11064)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9207\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t92.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.54s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1207.27s of the 1207.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9201\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t91.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 1111.83s of the 1111.6s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9235\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t73.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 1034.13s of the 1033.9s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_ray_fit pid=11697)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=11697)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=11696)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=11696)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=11698)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=11698)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=11824)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=11824)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=11920)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=11920)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9209\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t114.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.45s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 915.94s of the 915.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9207\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t87.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t2.33s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 824.2s of the 823.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\u001b[36m(_ray_fit pid=12223)\u001b[0m No improvement since epoch 14: early stopping\n",
      "\u001b[36m(_ray_fit pid=12223)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=12223)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=12220)\u001b[0m No improvement since epoch 17: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12220)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12220)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12397)\u001b[0m No improvement since epoch 1: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12397)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12397)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12473)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_ray_fit pid=12473)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=12473)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=12444)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_ray_fit pid=12444)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=12444)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=12369)\u001b[0m No improvement since epoch 13: early stopping\n",
      "\u001b[36m(_ray_fit pid=12369)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=12369)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9209\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t288.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.69s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 530.79s of the 530.57s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.39%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9234\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t216.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 310.85s of the 310.62s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9225\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t43.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.78s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 263.32s of the 263.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_ray_fit pid=13112)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=13112)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=13113)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=13113)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=13241)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=13241)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=13239)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=13239)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9198\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t140.13s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.66s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 119.21s of the 118.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.71%)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9226\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t83.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.77s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 31.11s of the 30.89s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=13297)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=13297)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9206\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t14.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t1.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 15.28s of the 15.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\u001b[36m(_ray_fit pid=13652)\u001b[0m \tRan out of time, early stopping on iteration 59.\n",
      "\u001b[36m(_ray_fit pid=13789)\u001b[0m \tRan out of time, early stopping on iteration 59.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9229\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t17.54s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -7.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \tEnsemble Weights: {'CatBoost_r177_BAG_L1': 0.227, 'CatBoost_BAG_L2': 0.227, 'CatBoost_r137_BAG_L1': 0.182, 'XGBoost_r33_BAG_L2': 0.136, 'NeuralNetFastAI_r191_BAG_L2': 0.091, 'CatBoost_r13_BAG_L1': 0.045, 'NeuralNetFastAI_r143_BAG_L1': 0.045, 'NeuralNetTorch_r22_BAG_L2': 0.045}\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.9243\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t2.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m AutoGluon training complete, total runtime = 5254.9s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 44.4 rows/s (3100 batch size)\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/Autogluon/student_medium/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_ray_fit pid=13803)\u001b[0m \tRan out of time, early stopping on iteration 61.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=183)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0            XGBoost_r89_BAG_L1       0.920430   0.921150     roc_auc        0.519671       0.513927    27.215620                 0.519671                0.513927          27.215620            1       True         29\n",
      "1           CatBoost_r13_BAG_L1       0.920418   0.923445     roc_auc        0.272432       0.548663   308.384539                 0.272432                0.548663         308.384539            1       True         25\n",
      "2               CatBoost_BAG_L1       0.920286   0.923307     roc_auc        1.102821       0.238673   135.709080                 1.102821                0.238673         135.709080            1       True          7\n",
      "3          CatBoost_r137_BAG_L2       0.920143   0.922869     roc_auc       27.786583      73.087063  3382.064570                 0.053634                0.365323          17.540522            2       True         63\n",
      "4           WeightedEnsemble_L2       0.920131   0.924153     roc_auc        4.079083      12.688981  1216.961001                 0.005805                0.004768           3.016448            2       True         42\n",
      "5          CatBoost_r177_BAG_L1       0.920085   0.923711     roc_auc        0.109132       0.220968    83.141834                 0.109132                0.220968          83.141834            1       True         14\n",
      "6          CatBoost_r177_BAG_L2       0.920074   0.923499     roc_auc       27.801709      72.898641  3438.339828                 0.068760                0.176901          73.815780            2       True         54\n",
      "7          CatBoost_r137_BAG_L1       0.920022   0.923622     roc_auc        0.133399       0.252746   183.999057                 0.133399                0.252746         183.999057            1       True         23\n",
      "8               CatBoost_BAG_L2       0.920010   0.923789     roc_auc       27.818050      72.934016  3468.440175                 0.085100                0.212276         103.916127            2       True         47\n",
      "9           CatBoost_r69_BAG_L1       0.919892   0.923386     roc_auc        0.126641       0.272172   147.794721                 0.126641                0.272172         147.794721            1       True         37\n",
      "10          WeightedEnsemble_L3       0.919861   0.924291     roc_auc       30.056062      77.061971  3983.953124                 0.005728                0.004629           2.613701            3       True         64\n",
      "11          CatBoost_r50_BAG_L1       0.919713   0.922096     roc_auc        0.145551       0.229353    48.940182                 0.145551                0.229353          48.940182            1       True         33\n",
      "12           CatBoost_r9_BAG_L1       0.919712   0.920986     roc_auc        0.187522       0.365938    93.158953                 0.187522                0.365938          93.158953            1       True         18\n",
      "13               XGBoost_BAG_L1       0.919683   0.919234     roc_auc        0.310426       0.473754    24.840532                 0.310426                0.473754          24.840532            1       True         11\n",
      "14           CatBoost_r9_BAG_L2       0.919673   0.923392     roc_auc       27.933001      73.068377  3580.635687                 0.200052                0.346636         216.111639            2       True         58\n",
      "15        NeuralNetTorch_BAG_L2       0.919519   0.920652     roc_auc       28.062655      73.260714  3457.349342                 0.329706                0.538974          92.825294            2       True         52\n",
      "16       NeuralNetFastAI_BAG_L2       0.919466   0.920899     roc_auc       28.543200      73.932001  3477.303758                 0.810251                1.210260         112.779710            2       True         50\n",
      "17    NeuralNetTorch_r79_BAG_L2       0.919374   0.920860     roc_auc       28.097261      73.176611  3478.834751                 0.364312                0.454871         114.310703            2       True         55\n",
      "18          LightGBM_r96_BAG_L2       0.919313   0.922533     roc_auc       28.101866      74.496970  3408.187492                 0.368917                1.775230          43.663444            2       True         59\n",
      "19        ExtraTreesGini_BAG_L2       0.919277   0.921668     roc_auc       28.011978      74.306161  3369.390481                 0.279029                1.584421           4.866433            2       True         48\n",
      "20            LightGBMXT_BAG_L2       0.918874   0.921867     roc_auc       27.896544      73.578203  3404.464340                 0.163594                0.856463          39.940292            2       True         43\n",
      "21        ExtraTrees_r42_BAG_L2       0.918767   0.920564     roc_auc       27.960769      74.070145  3378.581136                 0.227820                1.348404          14.057088            2       True         62\n",
      "22               XGBoost_BAG_L2       0.918625   0.922708     roc_auc       28.026508      73.141854  3395.202989                 0.293559                0.420114          30.678941            2       True         51\n",
      "23    NeuralNetTorch_r22_BAG_L2       0.918583   0.919770     roc_auc       28.124832      73.384311  3504.651535                 0.391883                0.662571         140.127487            2       True         60\n",
      "24          LightGBM_r96_BAG_L1       0.918282   0.921373     roc_auc        1.420251       8.168408    54.628587                 1.420251                8.168408          54.628587            1       True         19\n",
      "25            LightGBMXT_BAG_L1       0.918140   0.920377     roc_auc        1.278815       1.700382    25.662805                 1.278815                1.700382          25.662805            1       True          3\n",
      "26    NeuralNetTorch_r30_BAG_L1       0.918128   0.919105     roc_auc        0.391076       0.587059   160.989745                 0.391076                0.587059         160.989745            1       True         30\n",
      "27         LightGBM_r188_BAG_L1       0.918005   0.919936     roc_auc        0.579103       3.080825    35.279564                 0.579103                3.080825          35.279564            1       True         27\n",
      "28           XGBoost_r33_BAG_L1       0.917927   0.918270     roc_auc        1.316349       3.372636    58.135220                 1.316349                3.372636          58.135220            1       True         21\n",
      "29  NeuralNetFastAI_r191_BAG_L2       0.917842   0.920891     roc_auc       28.790767      74.416728  3653.365054                 1.057818                1.694988         288.841006            2       True         57\n",
      "30        ExtraTreesEntr_BAG_L2       0.917812   0.921675     roc_auc       28.007173      74.314573  3369.448812                 0.274224                1.592833           4.924764            2       True         49\n",
      "31           XGBoost_r33_BAG_L2       0.917673   0.922595     roc_auc       28.515532      74.487507  3448.454803                 0.782583                1.765767          83.930755            2       True         61\n",
      "32  NeuralNetFastAI_r191_BAG_L1       0.917487   0.916809     roc_auc        1.032559       1.564132   237.446509                 1.032559                1.564132         237.446509            1       True         17\n",
      "33    NeuralNetTorch_r14_BAG_L1       0.917461   0.919577     roc_auc        0.217680       0.337844    57.213955                 0.217680                0.337844          57.213955            1       True         39\n",
      "34    NeuralNetTorch_r79_BAG_L1       0.917333   0.919188     roc_auc        0.324673       0.453627   116.700312                 0.324673                0.453627         116.700312            1       True         15\n",
      "35    NeuralNetTorch_r22_BAG_L1       0.917323   0.916528     roc_auc        0.342341       0.559992   144.400893                 0.342341                0.559992         144.400893            1       True         20\n",
      "36  NeuralNetFastAI_r145_BAG_L1       0.917299   0.916940     roc_auc        1.367146       1.741437   230.924484                 1.367146                1.741437         230.924484            1       True         28\n",
      "37    NeuralNetTorch_r86_BAG_L1       0.917240   0.917586     roc_auc        0.358382       0.435616   176.181836                 0.358382                0.435616         176.181836            1       True         32\n",
      "38         LightGBM_r161_BAG_L1       0.917139   0.918105     roc_auc        2.886652      20.818097    86.716115                 2.886652               20.818097          86.716115            1       True         40\n",
      "39      RandomForestEntr_BAG_L2       0.917118   0.921451     roc_auc       27.956697      74.135151  3396.165409                 0.223748                1.413411          31.641361            2       True         46\n",
      "40         LightGBM_r131_BAG_L1       0.916962   0.917236     roc_auc        1.162011       6.389843    54.822334                 1.162011                6.389843          54.822334            1       True         16\n",
      "41  NeuralNetFastAI_r103_BAG_L1       0.916790   0.917548     roc_auc        0.814458       1.485297   124.881118                 0.814458                1.485297         124.881118            1       True         38\n",
      "42         LightGBM_r130_BAG_L1       0.916768   0.917392     roc_auc        0.370964       1.970996    28.893017                 0.370964                1.970996          28.893017            1       True         31\n",
      "43      RandomForestGini_BAG_L2       0.916737   0.919981     roc_auc       27.973362      74.191147  3389.801759                 0.240413                1.469407          25.277711            2       True         45\n",
      "44        NeuralNetTorch_BAG_L1       0.916660   0.918088     roc_auc        0.279950       0.420197    99.282681                 0.279950                0.420197          99.282681            1       True         12\n",
      "45  NeuralNetFastAI_r143_BAG_L1       0.916562   0.920139     roc_auc        0.422450       1.040053    53.461879                 0.422450                1.040053          53.461879            1       True         41\n",
      "46       NeuralNetFastAI_BAG_L1       0.916544   0.918982     roc_auc        1.398047       1.066221   100.041091                 1.398047                1.066221         100.041091            1       True         10\n",
      "47  NeuralNetFastAI_r102_BAG_L1       0.916500   0.915165     roc_auc        0.344763       0.528580    43.055860                 0.344763                0.528580          43.055860            1       True         24\n",
      "48      RandomForestEntr_BAG_L1       0.916369   0.914882     roc_auc        1.088983       1.086900     5.573451                 1.088983                1.086900           5.573451            1       True          6\n",
      "49              LightGBM_BAG_L1       0.916082   0.915943     roc_auc        0.264291       1.133457    25.178025                 0.264291                1.133457          25.178025            1       True          4\n",
      "50   NeuralNetFastAI_r11_BAG_L1       0.915967   0.912556     roc_auc        1.660928       2.173548   307.167843                 1.660928                2.173548         307.167843            1       True         34\n",
      "51        ExtraTreesEntr_BAG_L1       0.915461   0.914919     roc_auc        0.883088       1.201713     3.286383                 0.883088                1.201713           3.286383            1       True          9\n",
      "52         LightGBM_r131_BAG_L2       0.915243   0.920737     roc_auc       28.261436      75.052122  3452.265114                 0.528487                2.330382          87.741066            2       True         56\n",
      "53         LightGBMLarge_BAG_L1       0.915143   0.915080     roc_auc        0.427804       1.928044    36.308101                 0.427804                1.928044          36.308101            1       True         13\n",
      "54      RandomForestGini_BAG_L1       0.915043   0.914015     roc_auc        1.188071       1.095839     5.014784                 1.188071                1.095839           5.014784            1       True          5\n",
      "55              LightGBM_BAG_L2       0.914963   0.919779     roc_auc       27.885218      73.433720  3413.076971                 0.152268                0.711980          48.552923            2       True         44\n",
      "56        ExtraTreesGini_BAG_L1       0.914945   0.914398     roc_auc        1.772491       1.201582     3.320720                 1.772491                1.201582           3.320720            1       True          8\n",
      "57       ExtraTrees_r172_BAG_L1       0.914886   0.913901     roc_auc        0.230313       1.022669     5.372611                 0.230313                1.022669           5.372611            1       True         36\n",
      "58         LightGBMLarge_BAG_L2       0.914844   0.920095     roc_auc       28.060120      73.859693  3455.884777                 0.327171                1.137953          91.360729            2       True         53\n",
      "59        ExtraTrees_r42_BAG_L1       0.911881   0.910573     roc_auc        0.357074       1.126335     4.927427                 0.357074                1.126335           4.927427            1       True         22\n",
      "60     RandomForest_r195_BAG_L1       0.911418   0.908786     roc_auc        0.262146       1.086164    10.663348                 0.262146                1.086164          10.663348            1       True         26\n",
      "61          XGBoost_r194_BAG_L1       0.911011   0.909919     roc_auc        0.267715       0.395206    15.102066                 0.267715                0.395206          15.102066            1       True         35\n",
      "62        KNeighborsUnif_BAG_L1       0.814887   0.812606     roc_auc        0.071502       0.216245     0.670953                 0.071502                0.216245           0.670953            1       True          1\n",
      "63        KNeighborsDist_BAG_L1       0.811636   0.805758     roc_auc        0.043277       0.216601     0.035818                 0.043277                0.216601           0.035818            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t5298s\t = DyStack   runtime |\t15702s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 15702s\n",
      "AutoGluon will save models to \"/kaggle/working/Autogluon/student_medium\"\n",
      "Train Data Rows:    27901\n",
      "Train Data Columns: 14\n",
      "Label Column:       Depression\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29788.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.71 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 6 | ['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', ...]\n",
      "\t\t('object', []) : 8 | ['Name', 'Gender', 'City', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 5 | ['Name', 'City', 'Sleep Duration', 'Dietary Habits', 'Degree']\n",
      "\t\t('float', [])     : 6 | ['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', ...]\n",
      "\t\t('int', ['bool']) : 3 | ['Gender', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t0.4s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.52 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 15701.25s of the 15701.23s of remaining time.\n",
      "\t0.8135\t = Validation score   (roc_auc)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 15697.78s of the 15697.76s of remaining time.\n",
      "\t0.8072\t = Validation score   (roc_auc)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 15697.45s of the 15697.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9202\t = Validation score   (roc_auc)\n",
      "\t25.76s\t = Training   runtime\n",
      "\t1.82s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 15667.93s of the 15667.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9161\t = Validation score   (roc_auc)\n",
      "\t27.53s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 15636.17s of the 15636.15s of remaining time.\n",
      "\t0.9144\t = Validation score   (roc_auc)\n",
      "\t5.68s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 15628.67s of the 15628.64s of remaining time.\n",
      "\t0.9153\t = Validation score   (roc_auc)\n",
      "\t5.77s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 15621.09s of the 15621.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.923\t = Validation score   (roc_auc)\n",
      "\t169.08s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 15447.81s of the 15447.78s of remaining time.\n",
      "\t0.9147\t = Validation score   (roc_auc)\n",
      "\t3.81s\t = Training   runtime\n",
      "\t1.37s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 15441.87s of the 15441.84s of remaining time.\n",
      "\t0.9147\t = Validation score   (roc_auc)\n",
      "\t3.85s\t = Training   runtime\n",
      "\t1.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 15435.92s of the 15435.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9182\t = Validation score   (roc_auc)\n",
      "\t116.79s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 15315.61s of the 15315.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9195\t = Validation score   (roc_auc)\n",
      "\t26.2s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 15285.62s of the 15285.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9178\t = Validation score   (roc_auc)\n",
      "\t103.65s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 15178.23s of the 15178.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.9153\t = Validation score   (roc_auc)\n",
      "\t38.93s\t = Training   runtime\n",
      "\t2.63s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 15134.52s of the 15134.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9235\t = Validation score   (roc_auc)\n",
      "\t95.24s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 15035.52s of the 15035.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9198\t = Validation score   (roc_auc)\n",
      "\t130.7s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 14900.96s of the 14900.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9178\t = Validation score   (roc_auc)\n",
      "\t60.91s\t = Training   runtime\n",
      "\t9.57s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 14834.37s of the 14834.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9169\t = Validation score   (roc_auc)\n",
      "\t278.59s\t = Training   runtime\n",
      "\t1.57s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 14551.15s of the 14551.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.9212\t = Validation score   (roc_auc)\n",
      "\t100.74s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 14446.33s of the 14446.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.921\t = Validation score   (roc_auc)\n",
      "\t61.56s\t = Training   runtime\n",
      "\t10.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 14379.76s of the 14379.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.919\t = Validation score   (roc_auc)\n",
      "\t158.51s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 14217.3s of the 14217.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\t0.9185\t = Validation score   (roc_auc)\n",
      "\t63.03s\t = Training   runtime\n",
      "\t3.8s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 14150.27s of the 14150.24s of remaining time.\n",
      "\t0.9109\t = Validation score   (roc_auc)\n",
      "\t5.8s\t = Training   runtime\n",
      "\t1.31s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 14142.58s of the 14142.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9232\t = Validation score   (roc_auc)\n",
      "\t180.53s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 13958.17s of the 13958.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9154\t = Validation score   (roc_auc)\n",
      "\t44.79s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 13909.56s of the 13909.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.9231\t = Validation score   (roc_auc)\n",
      "\t334.7s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 13570.31s of the 13570.29s of remaining time.\n",
      "\t0.909\t = Validation score   (roc_auc)\n",
      "\t12.14s\t = Training   runtime\n",
      "\t1.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 13556.17s of the 13556.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.9195\t = Validation score   (roc_auc)\n",
      "\t37.77s\t = Training   runtime\n",
      "\t3.66s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 13513.5s of the 13513.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9168\t = Validation score   (roc_auc)\n",
      "\t282.58s\t = Training   runtime\n",
      "\t2.25s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 13227.01s of the 13226.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9211\t = Validation score   (roc_auc)\n",
      "\t28.39s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 13194.2s of the 13194.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9175\t = Validation score   (roc_auc)\n",
      "\t171.25s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 13018.78s of the 13018.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9178\t = Validation score   (roc_auc)\n",
      "\t27.64s\t = Training   runtime\n",
      "\t1.96s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 12987.16s of the 12987.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.918\t = Validation score   (roc_auc)\n",
      "\t195.79s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 12787.73s of the 12787.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9219\t = Validation score   (roc_auc)\n",
      "\t51.9s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 12732.06s of the 12732.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.914\t = Validation score   (roc_auc)\n",
      "\t347.42s\t = Training   runtime\n",
      "\t2.26s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 12380.74s of the 12380.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.9108\t = Validation score   (roc_auc)\n",
      "\t16.24s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 12360.63s of the 12360.61s of remaining time.\n",
      "\t0.9143\t = Validation score   (roc_auc)\n",
      "\t5.73s\t = Training   runtime\n",
      "\t1.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 12353.4s of the 12353.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9232\t = Validation score   (roc_auc)\n",
      "\t151.42s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 12198.48s of the 12198.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9157\t = Validation score   (roc_auc)\n",
      "\t145.33s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 12049.42s of the 12049.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9186\t = Validation score   (roc_auc)\n",
      "\t62.63s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 11982.83s of the 11982.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.9184\t = Validation score   (roc_auc)\n",
      "\t86.95s\t = Training   runtime\n",
      "\t22.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 11886.13s of the 11886.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.92\t = Validation score   (roc_auc)\n",
      "\t79.28s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 11802.95s of the 11802.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9218\t = Validation score   (roc_auc)\n",
      "\t70.35s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 11728.77s of the 11728.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.919\t = Validation score   (roc_auc)\n",
      "\t51.2s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 11674.02s of the 11673.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.9209\t = Validation score   (roc_auc)\n",
      "\t194.88s\t = Training   runtime\n",
      "\t89.24s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 11461.24s of the 11461.22s of remaining time.\n",
      "\t0.9109\t = Validation score   (roc_auc)\n",
      "\t11.97s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 11447.69s of the 11447.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.9227\t = Validation score   (roc_auc)\n",
      "\t98.76s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 11345.5s of the 11345.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.919\t = Validation score   (roc_auc)\n",
      "\t304.21s\t = Training   runtime\n",
      "\t1.84s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 11037.5s of the 11037.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9176\t = Validation score   (roc_auc)\n",
      "\t102.36s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 10931.24s of the 10931.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.9171\t = Validation score   (roc_auc)\n",
      "\t97.16s\t = Training   runtime\n",
      "\t7.45s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 10829.08s of the 10829.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9183\t = Validation score   (roc_auc)\n",
      "\t42.46s\t = Training   runtime\n",
      "\t4.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 10782.83s of the 10782.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9058\t = Validation score   (roc_auc)\n",
      "\t323.84s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 10454.94s of the 10454.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.9226\t = Validation score   (roc_auc)\n",
      "\t203.69s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 10247.12s of the 10247.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9201\t = Validation score   (roc_auc)\n",
      "\t100.99s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 10141.96s of the 10141.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9151\t = Validation score   (roc_auc)\n",
      "\t64.01s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 10073.34s of the 10073.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9224\t = Validation score   (roc_auc)\n",
      "\t55.07s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r49_BAG_L1 ... Training model for up to 10014.17s of the 10014.15s of remaining time.\n",
      "\t0.9147\t = Validation score   (roc_auc)\n",
      "\t4.02s\t = Training   runtime\n",
      "\t1.37s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 10008.0s of the 10007.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.9155\t = Validation score   (roc_auc)\n",
      "\t62.88s\t = Training   runtime\n",
      "\t6.53s\t = Validation runtime\n",
      "Fitting model: RandomForest_r127_BAG_L1 ... Training model for up to 9940.24s of the 9940.21s of remaining time.\n",
      "\t0.912\t = Validation score   (roc_auc)\n",
      "\t13.95s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 9924.89s of the 9924.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9156\t = Validation score   (roc_auc)\n",
      "\t143.58s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: RandomForest_r34_BAG_L1 ... Training model for up to 9777.76s of the 9777.73s of remaining time.\n",
      "\t0.9151\t = Validation score   (roc_auc)\n",
      "\t7.89s\t = Training   runtime\n",
      "\t0.96s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 9768.72s of the 9768.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9207\t = Validation score   (roc_auc)\n",
      "\t29.7s\t = Training   runtime\n",
      "\t4.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 9735.27s of the 9735.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9202\t = Validation score   (roc_auc)\n",
      "\t231.86s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: CatBoost_r128_BAG_L1 ... Training model for up to 9499.67s of the 9499.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.921\t = Validation score   (roc_auc)\n",
      "\t81.98s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 9413.78s of the 9413.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9192\t = Validation score   (roc_auc)\n",
      "\t60.67s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 9349.4s of the 9349.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9202\t = Validation score   (roc_auc)\n",
      "\t109.24s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r4_BAG_L1 ... Training model for up to 9235.72s of the 9235.7s of remaining time.\n",
      "\t0.9155\t = Validation score   (roc_auc)\n",
      "\t5.08s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 9229.4s of the 9229.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9206\t = Validation score   (roc_auc)\n",
      "\t75.61s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 9149.38s of the 9149.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9162\t = Validation score   (roc_auc)\n",
      "\t74.94s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBM_r30_BAG_L1 ... Training model for up to 9070.1s of the 9070.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9199\t = Validation score   (roc_auc)\n",
      "\t88.6s\t = Training   runtime\n",
      "\t17.91s\t = Validation runtime\n",
      "Fitting model: XGBoost_r49_BAG_L1 ... Training model for up to 8976.81s of the 8976.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.9199\t = Validation score   (roc_auc)\n",
      "\t38.46s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: CatBoost_r5_BAG_L1 ... Training model for up to 8934.65s of the 8934.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9236\t = Validation score   (roc_auc)\n",
      "\t156.57s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 8773.72s of the 8773.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9173\t = Validation score   (roc_auc)\n",
      "\t99.33s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 8670.6s of the 8670.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9154\t = Validation score   (roc_auc)\n",
      "\t58.54s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: CatBoost_r143_BAG_L1 ... Training model for up to 8607.85s of the 8607.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.9231\t = Validation score   (roc_auc)\n",
      "\t78.28s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r178_BAG_L1 ... Training model for up to 8525.58s of the 8525.56s of remaining time.\n",
      "\t0.915\t = Validation score   (roc_auc)\n",
      "\t5.21s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: RandomForest_r166_BAG_L1 ... Training model for up to 8518.86s of the 8518.84s of remaining time.\n",
      "\t0.9144\t = Validation score   (roc_auc)\n",
      "\t5.58s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: XGBoost_r31_BAG_L1 ... Training model for up to 8511.49s of the 8511.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9217\t = Validation score   (roc_auc)\n",
      "\t152.81s\t = Training   runtime\n",
      "\t3.24s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 8354.81s of the 8354.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9176\t = Validation score   (roc_auc)\n",
      "\t127.88s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 8223.19s of the 8223.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9186\t = Validation score   (roc_auc)\n",
      "\t211.89s\t = Training   runtime\n",
      "\t2.31s\t = Validation runtime\n",
      "Fitting model: CatBoost_r60_BAG_L1 ... Training model for up to 8006.93s of the 8006.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.923\t = Validation score   (roc_auc)\n",
      "\t127.73s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: RandomForest_r15_BAG_L1 ... Training model for up to 7875.31s of the 7875.28s of remaining time.\n",
      "\t0.9116\t = Validation score   (roc_auc)\n",
      "\t11.07s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_r135_BAG_L1 ... Training model for up to 7862.57s of the 7862.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.9163\t = Validation score   (roc_auc)\n",
      "\t40.02s\t = Training   runtime\n",
      "\t2.57s\t = Validation runtime\n",
      "Fitting model: XGBoost_r22_BAG_L1 ... Training model for up to 7818.37s of the 7818.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9206\t = Validation score   (roc_auc)\n",
      "\t30.17s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 7783.77s of the 7783.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9177\t = Validation score   (roc_auc)\n",
      "\t190.57s\t = Training   runtime\n",
      "\t2.0s\t = Validation runtime\n",
      "Fitting model: CatBoost_r6_BAG_L1 ... Training model for up to 7588.87s of the 7588.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9222\t = Validation score   (roc_auc)\n",
      "\t46.64s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 7537.28s of the 7537.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9168\t = Validation score   (roc_auc)\n",
      "\t342.48s\t = Training   runtime\n",
      "\t2.4s\t = Validation runtime\n",
      "Fitting model: LightGBM_r121_BAG_L1 ... Training model for up to 7190.91s of the 7190.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.9184\t = Validation score   (roc_auc)\n",
      "\t87.22s\t = Training   runtime\n",
      "\t21.81s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 7095.33s of the 7095.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9141\t = Validation score   (roc_auc)\n",
      "\t72.39s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: CatBoost_r180_BAG_L1 ... Training model for up to 7018.84s of the 7018.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.9211\t = Validation score   (roc_auc)\n",
      "\t59.6s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 6955.03s of the 6955.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9182\t = Validation score   (roc_auc)\n",
      "\t65.99s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r197_BAG_L1 ... Training model for up to 6885.46s of the 6885.44s of remaining time.\n",
      "\t0.9105\t = Validation score   (roc_auc)\n",
      "\t7.21s\t = Training   runtime\n",
      "\t1.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L1 ... Training model for up to 6876.53s of the 6876.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9204\t = Validation score   (roc_auc)\n",
      "\t660.61s\t = Training   runtime\n",
      "\t2.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L1 ... Training model for up to 6211.8s of the 6211.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9139\t = Validation score   (roc_auc)\n",
      "\t57.11s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: RandomForest_r16_BAG_L1 ... Training model for up to 6149.2s of the 6149.17s of remaining time.\n",
      "\t0.9077\t = Validation score   (roc_auc)\n",
      "\t16.97s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L1 ... Training model for up to 6130.62s of the 6130.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9182\t = Validation score   (roc_auc)\n",
      "\t141.29s\t = Training   runtime\n",
      "\t1.31s\t = Validation runtime\n",
      "Fitting model: CatBoost_r12_BAG_L1 ... Training model for up to 5985.64s of the 5985.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.9233\t = Validation score   (roc_auc)\n",
      "\t206.51s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L1 ... Training model for up to 5774.83s of the 5774.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9179\t = Validation score   (roc_auc)\n",
      "\t148.79s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L1 ... Training model for up to 5622.36s of the 5622.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9197\t = Validation score   (roc_auc)\n",
      "\t108.66s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r126_BAG_L1 ... Training model for up to 5508.83s of the 5508.8s of remaining time.\n",
      "\t0.9164\t = Validation score   (roc_auc)\n",
      "\t3.55s\t = Training   runtime\n",
      "\t1.22s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L1 ... Training model for up to 5503.56s of the 5503.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9202\t = Validation score   (roc_auc)\n",
      "\t93.3s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L1 ... Training model for up to 5406.81s of the 5406.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9194\t = Validation score   (roc_auc)\n",
      "\t203.3s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_r163_BAG_L1 ... Training model for up to 5199.63s of the 5199.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9222\t = Validation score   (roc_auc)\n",
      "\t42.81s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r198_BAG_L1 ... Training model for up to 5153.32s of the 5153.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9231\t = Validation score   (roc_auc)\n",
      "\t202.81s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L1 ... Training model for up to 4946.89s of the 4946.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9208\t = Validation score   (roc_auc)\n",
      "\t66.99s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L1 ... Training model for up to 4876.09s of the 4876.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9182\t = Validation score   (roc_auc)\n",
      "\t64.84s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: XGBoost_r95_BAG_L1 ... Training model for up to 4807.48s of the 4807.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.9206\t = Validation score   (roc_auc)\n",
      "\t31.74s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: XGBoost_r34_BAG_L1 ... Training model for up to 4772.15s of the 4772.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\t0.9192\t = Validation score   (roc_auc)\n",
      "\t49.31s\t = Training   runtime\n",
      "\t2.33s\t = Validation runtime\n",
      "Fitting model: LightGBM_r42_BAG_L1 ... Training model for up to 4718.84s of the 4718.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.9198\t = Validation score   (roc_auc)\n",
      "\t25.39s\t = Training   runtime\n",
      "\t2.41s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L1 ... Training model for up to 4689.44s of the 4689.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9182\t = Validation score   (roc_auc)\n",
      "\t143.94s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L1 ... Training model for up to 4541.43s of the 4541.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9181\t = Validation score   (roc_auc)\n",
      "\t137.22s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 1570.12s of the 4400.07s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 0.318, 'CatBoost_r5_BAG_L1': 0.227, 'CatBoost_r12_BAG_L1': 0.182, 'NeuralNetTorch_r31_BAG_L1': 0.136, 'NeuralNetFastAI_r143_BAG_L1': 0.045, 'NeuralNetTorch_r143_BAG_L1': 0.045, 'NeuralNetFastAI_r4_BAG_L1': 0.045}\n",
      "\t0.924\t = Validation score   (roc_auc)\n",
      "\t3.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11304.77s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 928.3 rows/s (3488 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/Autogluon/student_medium\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 33s, sys: 43.9 s, total: 10min 17s\n",
      "Wall time: 4h 36min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7c7e99b16ce0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "from autogluon.tabular import TabularPredictor\n",
    " \n",
    "predictor_student = TabularPredictor(path = '/kaggle/working/Autogluon/student_medium',\n",
    "                                      label='Depression', \n",
    "                              problem_type = 'binary', \n",
    "                              eval_metric = 'roc_auc',  \n",
    "                              sample_weight = 'auto_weight')\n",
    "# here we can use eval_metric = 'accuracy', because the sub data set is balanced \n",
    "\n",
    "predictor_student.fit(train_data= train_df_student.to_pandas(), \n",
    "                       auto_stack = True, \n",
    "                       presets='best_quality',\n",
    "# best_quality,  medium_quality                         \n",
    "                       time_limit = 21000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59abaaff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T23:15:16.126180Z",
     "iopub.status.busy": "2024-11-09T23:15:16.125076Z",
     "iopub.status.idle": "2024-11-10T05:05:35.516822Z",
     "shell.execute_reply": "2024-11-10T05:05:35.515013Z"
    },
    "papermill": {
     "duration": 21019.571371,
     "end_time": "2024-11-10T05:05:35.603431",
     "exception": false,
     "start_time": "2024-11-09T23:15:16.032060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.65 GB / 31.36 GB (94.5%)\n",
      "Disk Space Avail:   14.74 GB / 19.52 GB (75.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 5250s of the 21000s of remaining time (25%).\n",
      "\t\tContext path: \"/kaggle/working/Autogluon/professional_best/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                        model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0             CatBoost_BAG_L2       0.972839   0.973045     roc_auc       17.962160      56.667873  3721.798904                 0.170375                0.399172         286.317753            2       True         22\n",
      "1         WeightedEnsemble_L3       0.972813   0.973674     roc_auc       19.690105      66.702035  3953.480703                 0.006908                0.018724          11.155157            3       True         31\n",
      "2             CatBoost_BAG_L1       0.972777   0.973084     roc_auc        1.362901       1.457390  1118.823754                 1.362901                1.457390        1118.823754            1       True          7\n",
      "3        CatBoost_r177_BAG_L1       0.972750   0.973200     roc_auc        0.549612       1.138762   689.142617                 0.549612                1.138762         689.142617            1       True         14\n",
      "4        CatBoost_r177_BAG_L2       0.972716   0.972871     roc_auc       17.911504      56.554418  3560.358235                 0.119719                0.285717         124.877084            2       True         29\n",
      "5         WeightedEnsemble_L2       0.972646   0.973634     roc_auc       10.361259      26.265514  3063.627346                 0.006629                0.019845           7.775744            2       True         17\n",
      "6   NeuralNetTorch_r79_BAG_L2       0.972552   0.970732     roc_auc       19.098243      58.598486  3487.623538                 1.306458                2.329785          52.142387            2       True         30\n",
      "7              XGBoost_BAG_L2       0.972288   0.972941     roc_auc       18.450509      57.487700  3552.724647                 0.658724                1.218999         117.243495            2       True         26\n",
      "8              XGBoost_BAG_L1       0.972122   0.971407     roc_auc        1.182976       1.844620   222.425110                 1.182976                1.844620         222.425110            1       True         11\n",
      "9           LightGBMXT_BAG_L2       0.972079   0.972184     roc_auc       18.244801      59.159580  3493.133317                 0.453016                2.890879          57.652165            2       True         18\n",
      "10      NeuralNetTorch_BAG_L2       0.971554   0.970996     roc_auc       19.035457      58.166126  3772.427217                 1.243672                1.897425         336.946066            2       True         27\n",
      "11          LightGBMXT_BAG_L1       0.971517   0.971661     roc_auc        1.911211       5.820321    66.576586                 1.911211                5.820321          66.576586            1       True          3\n",
      "12      ExtraTreesGini_BAG_L2       0.971380   0.968307     roc_auc       18.220554      61.218267  3450.951705                 0.428770                4.949566          15.470554            2       True         23\n",
      "13     NeuralNetFastAI_BAG_L2       0.971306   0.969603     roc_auc       20.358973      59.657380  3859.269009                 2.567188                3.388679         423.787858            2       True         25\n",
      "14       LightGBMLarge_BAG_L2       0.971137   0.971535     roc_auc       18.423066      59.877097  3524.944869                 0.631281                3.608396          89.463717            2       True         28\n",
      "15       LightGBM_r131_BAG_L1       0.971136   0.970322     roc_auc        1.239780       9.616636    59.506903                 1.239780                9.616636          59.506903            1       True         16\n",
      "16      ExtraTreesEntr_BAG_L2       0.971128   0.968921     roc_auc       18.222816      61.456744  3449.300580                 0.431031                5.188043          13.819429            2       True         24\n",
      "17            LightGBM_BAG_L2       0.970821   0.971496     roc_auc       18.139436      57.790536  3490.394628                 0.347651                1.521835          54.913476            2       True         19\n",
      "18     NeuralNetFastAI_BAG_L1       0.970758   0.969096     roc_auc        3.105623       3.695079   449.464232                 3.105623                3.695079         449.464232            1       True         10\n",
      "19  NeuralNetTorch_r79_BAG_L1       0.970700   0.969834     roc_auc        0.811300       1.867455   277.726159                 0.811300                1.867455         277.726159            1       True         15\n",
      "20       LightGBMLarge_BAG_L1       0.970413   0.969607     roc_auc        1.217945       7.252833    82.439582                 1.217945                7.252833          82.439582            1       True         13\n",
      "21            LightGBM_BAG_L1       0.970097   0.969870     roc_auc        0.774176       4.603088    54.165772                 0.774176                4.603088          54.165772            1       True          4\n",
      "22      NeuralNetTorch_BAG_L1       0.969534   0.969966     roc_auc        0.750105       1.135624   361.034488                 0.750105                1.135624         361.034488            1       True         12\n",
      "23    RandomForestGini_BAG_L2       0.969261   0.967071     roc_auc       18.130394      60.929910  3486.311475                 0.338609                4.661209          50.830324            2       True         20\n",
      "24    RandomForestEntr_BAG_L2       0.969143   0.967840     roc_auc       18.100367      60.842067  3486.442049                 0.308582                4.573365          50.960897            2       True         21\n",
      "25    RandomForestEntr_BAG_L1       0.969056   0.965586     roc_auc        1.298000       3.529768    15.347857                 1.298000                3.529768          15.347857            1       True          6\n",
      "26      ExtraTreesGini_BAG_L1       0.967582   0.965039     roc_auc        1.054417       4.821944    10.336625                 1.054417                4.821944          10.336625            1       True          8\n",
      "27    RandomForestGini_BAG_L1       0.967492   0.964533     roc_auc        1.544403       3.615801    16.956303                 1.544403                3.615801          16.956303            1       True          5\n",
      "28      ExtraTreesEntr_BAG_L1       0.966311   0.966681     roc_auc        0.645932       3.878205    10.644185                 0.645932                3.878205          10.644185            1       True          9\n",
      "29      KNeighborsUnif_BAG_L1       0.892952   0.889494     roc_auc        0.185727       1.038419     0.734297                 0.185727                1.038419           0.734297            1       True          1\n",
      "30      KNeighborsDist_BAG_L1       0.850539   0.841104     roc_auc        0.157676       0.952756     0.156682                 0.157676                0.952756           0.156682            1       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t5289s\t = DyStack   runtime |\t15711s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 15711s\n",
      "AutoGluon will save models to \"/kaggle/working/Autogluon/professional_best\"\n",
      "Train Data Rows:    112799\n",
      "Train Data Columns: 14\n",
      "Label Column:       Depression\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29291.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 65.41 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 5 | ['Age', 'Work Pressure', 'Job Satisfaction', 'Work/Study Hours', 'Financial Stress']\n",
      "\t\t('object', []) : 9 | ['Name', 'Gender', 'City', 'Profession', 'Sleep Duration', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t('float', [])     : 5 | ['Age', 'Work Pressure', 'Job Satisfaction', 'Work/Study Hours', 'Financial Stress']\n",
      "\t\t('int', ['bool']) : 3 | ['Gender', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t1.5s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.38 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.65s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 10470.07s of the 15709.02s of remaining time.\n",
      "\t0.8888\t = Validation score   (roc_auc)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 10468.88s of the 15707.82s of remaining time.\n",
      "\t0.8402\t = Validation score   (roc_auc)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 10467.72s of the 15706.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t0.9713\t = Validation score   (roc_auc)\n",
      "\t65.95s\t = Training   runtime\n",
      "\t7.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 10397.49s of the 15636.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.9696\t = Validation score   (roc_auc)\n",
      "\t58.07s\t = Training   runtime\n",
      "\t5.06s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 10335.25s of the 15574.19s of remaining time.\n",
      "\t0.9658\t = Validation score   (roc_auc)\n",
      "\t18.27s\t = Training   runtime\n",
      "\t3.88s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 10312.41s of the 15551.36s of remaining time.\n",
      "\t0.9658\t = Validation score   (roc_auc)\n",
      "\t17.23s\t = Training   runtime\n",
      "\t3.83s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 10290.71s of the 15529.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.9729\t = Validation score   (roc_auc)\n",
      "\t1208.18s\t = Training   runtime\n",
      "\t1.52s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 9078.85s of the 14317.8s of remaining time.\n",
      "\t0.9659\t = Validation score   (roc_auc)\n",
      "\t11.34s\t = Training   runtime\n",
      "\t4.17s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 9062.35s of the 14301.29s of remaining time.\n",
      "\t0.9661\t = Validation score   (roc_auc)\n",
      "\t10.89s\t = Training   runtime\n",
      "\t4.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 9045.97s of the 14284.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\t0.9686\t = Validation score   (roc_auc)\n",
      "\t462.24s\t = Training   runtime\n",
      "\t3.93s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 8579.75s of the 13818.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\t0.9715\t = Validation score   (roc_auc)\n",
      "\t262.35s\t = Training   runtime\n",
      "\t2.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 8312.65s of the 13551.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.9694\t = Validation score   (roc_auc)\n",
      "\t417.86s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 7890.31s of the 13129.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\t0.9693\t = Validation score   (roc_auc)\n",
      "\t86.39s\t = Training   runtime\n",
      "\t7.36s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 7799.31s of the 13038.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.973\t = Validation score   (roc_auc)\n",
      "\t632.44s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 7162.95s of the 12401.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.9695\t = Validation score   (roc_auc)\n",
      "\t481.51s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 6677.28s of the 11916.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.971\t = Validation score   (roc_auc)\n",
      "\t209.49s\t = Training   runtime\n",
      "\t42.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 6461.12s of the 11700.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\t0.9706\t = Validation score   (roc_auc)\n",
      "\t1370.68s\t = Training   runtime\n",
      "\t6.0s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 5086.13s of the 10325.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t0.9716\t = Validation score   (roc_auc)\n",
      "\t312.78s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 4769.42s of the 10008.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t0.9723\t = Validation score   (roc_auc)\n",
      "\t199.34s\t = Training   runtime\n",
      "\t39.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 4564.34s of the 9803.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.9699\t = Validation score   (roc_auc)\n",
      "\t608.23s\t = Training   runtime\n",
      "\t2.02s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 3952.32s of the 9191.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
      "\t0.9717\t = Validation score   (roc_auc)\n",
      "\t817.59s\t = Training   runtime\n",
      "\t19.68s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 3128.04s of the 8366.98s of remaining time.\n",
      "\t0.9644\t = Validation score   (roc_auc)\n",
      "\t20.78s\t = Training   runtime\n",
      "\t3.75s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 3102.82s of the 8341.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t0.9731\t = Validation score   (roc_auc)\n",
      "\t1395.49s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1703.83s of the 6942.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\t0.9673\t = Validation score   (roc_auc)\n",
      "\t152.81s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 1547.28s of the 6786.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t0.9728\t = Validation score   (roc_auc)\n",
      "\t1246.32s\t = Training   runtime\n",
      "\t2.41s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 296.96s of the 5535.91s of remaining time.\n",
      "\t0.9603\t = Validation score   (roc_auc)\n",
      "\t51.34s\t = Training   runtime\n",
      "\t3.53s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 241.22s of the 5480.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.9717\t = Validation score   (roc_auc)\n",
      "\t92.2s\t = Training   runtime\n",
      "\t12.71s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 143.35s of the 5382.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\t0.9675\t = Validation score   (roc_auc)\n",
      "\t100.86s\t = Training   runtime\n",
      "\t9.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 37.86s of the 5276.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\t0.9673\t = Validation score   (roc_auc)\n",
      "\t35.8s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 1047.01s of the 5236.18s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r137_BAG_L1': 0.4, 'CatBoost_r177_BAG_L1': 0.16, 'LightGBM_r96_BAG_L1': 0.12, 'XGBoost_r33_BAG_L1': 0.12, 'NeuralNetFastAI_BAG_L1': 0.08, 'RandomForestGini_BAG_L1': 0.04, 'NeuralNetFastAI_r191_BAG_L1': 0.04, 'NeuralNetTorch_r22_BAG_L1': 0.04}\n",
      "\t0.9734\t = Validation score   (roc_auc)\n",
      "\t12.23s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 5223.9s of the 5223.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
      "\t0.972\t = Validation score   (roc_auc)\n",
      "\t76.37s\t = Training   runtime\n",
      "\t2.98s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 5143.29s of the 5143.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.42%)\n",
      "\t0.9715\t = Validation score   (roc_auc)\n",
      "\t82.57s\t = Training   runtime\n",
      "\t2.24s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 5056.71s of the 5056.54s of remaining time.\n",
      "\t0.9672\t = Validation score   (roc_auc)\n",
      "\t81.76s\t = Training   runtime\n",
      "\t5.62s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 4968.81s of the 4968.64s of remaining time.\n",
      "\t0.9683\t = Validation score   (roc_auc)\n",
      "\t82.94s\t = Training   runtime\n",
      "\t5.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 4879.86s of the 4879.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
      "\t0.9732\t = Validation score   (roc_auc)\n",
      "\t253.12s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 4623.0s of the 4622.82s of remaining time.\n",
      "\t0.9689\t = Validation score   (roc_auc)\n",
      "\t17.09s\t = Training   runtime\n",
      "\t6.2s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 4598.95s of the 4598.78s of remaining time.\n",
      "\t0.9687\t = Validation score   (roc_auc)\n",
      "\t16.64s\t = Training   runtime\n",
      "\t5.95s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 4575.66s of the 4575.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.66%)\n",
      "\t0.9692\t = Validation score   (roc_auc)\n",
      "\t449.04s\t = Training   runtime\n",
      "\t3.49s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 4122.39s of the 4122.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.63%)\n",
      "\t0.9729\t = Validation score   (roc_auc)\n",
      "\t154.01s\t = Training   runtime\n",
      "\t1.53s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3963.38s of the 3963.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\t0.9715\t = Validation score   (roc_auc)\n",
      "\t380.36s\t = Training   runtime\n",
      "\t2.5s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 3578.99s of the 3578.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
      "\t0.9715\t = Validation score   (roc_auc)\n",
      "\t130.55s\t = Training   runtime\n",
      "\t3.33s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 3444.26s of the 3444.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
      "\t0.9731\t = Validation score   (roc_auc)\n",
      "\t176.03s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 3264.41s of the 3264.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\t0.9712\t = Validation score   (roc_auc)\n",
      "\t454.14s\t = Training   runtime\n",
      "\t3.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 2806.2s of the 2806.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
      "\t0.972\t = Validation score   (roc_auc)\n",
      "\t215.47s\t = Training   runtime\n",
      "\t8.86s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 2585.95s of the 2585.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.67%)\n",
      "\t0.9708\t = Validation score   (roc_auc)\n",
      "\t1166.44s\t = Training   runtime\n",
      "\t6.41s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 1414.84s of the 1414.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.61%)\n",
      "\t0.9733\t = Validation score   (roc_auc)\n",
      "\t223.23s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 1187.55s of the 1187.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
      "\t0.9725\t = Validation score   (roc_auc)\n",
      "\t144.32s\t = Training   runtime\n",
      "\t8.49s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 1038.96s of the 1038.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\t0.9706\t = Validation score   (roc_auc)\n",
      "\t603.83s\t = Training   runtime\n",
      "\t4.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 430.89s of the 430.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.95%)\n",
      "\t0.9727\t = Validation score   (roc_auc)\n",
      "\t351.18s\t = Training   runtime\n",
      "\t7.66s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 74.86s of the 74.68s of remaining time.\n",
      "\t0.9672\t = Validation score   (roc_auc)\n",
      "\t53.12s\t = Training   runtime\n",
      "\t5.83s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 15.28s of the 15.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
      "\t0.9704\t = Validation score   (roc_auc)\n",
      "\t15.98s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 522.39s of the -6.82s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r137_BAG_L1': 0.32, 'CatBoost_r9_BAG_L2': 0.2, 'XGBoost_BAG_L2': 0.16, 'CatBoost_BAG_L2': 0.08, 'NeuralNetFastAI_BAG_L1': 0.04, 'NeuralNetFastAI_r191_BAG_L1': 0.04, 'XGBoost_r33_BAG_L1': 0.04, 'ExtraTreesEntr_BAG_L2': 0.04, 'NeuralNetFastAI_BAG_L2': 0.04, 'NeuralNetTorch_r22_BAG_L2': 0.04}\n",
      "\t0.9735\t = Validation score   (roc_auc)\n",
      "\t12.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15729.88s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 77.1 rows/s (14100 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/Autogluon/professional_best\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 20s, sys: 33.8 s, total: 26min 54s\n",
      "Wall time: 5h 50min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7c7e8e6af2e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "predictor_prof = TabularPredictor(path = '/kaggle/working/Autogluon/professional_best',\n",
    "                                label='Depression', \n",
    "                              problem_type = 'binary', \n",
    "                              eval_metric = 'roc_auc',  \n",
    "                              sample_weight = 'auto_weight')\n",
    "# # here we can use eval_metric = 'oc_auc', because the sub data set   is not balanced \n",
    "\n",
    "predictor_prof.fit(train_data= train_df_professional.to_pandas(), \n",
    "                      \n",
    "                      auto_stack = True, \n",
    "                      presets='best_quality',\n",
    "# best_quality,  medium_quality                     \n",
    "                       time_limit = 21000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87486c73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T05:05:35.844681Z",
     "iopub.status.busy": "2024-11-10T05:05:35.843715Z",
     "iopub.status.idle": "2024-11-10T05:05:35.852904Z",
     "shell.execute_reply": "2024-11-10T05:05:35.851840Z"
    },
    "papermill": {
     "duration": 0.134147,
     "end_time": "2024-11-10T05:05:35.855725",
     "exception": false,
     "start_time": "2024-11-10T05:05:35.721578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from autogluon.tabular import TabularPredictor\n",
    "# import zipfile\n",
    "\n",
    "# file_path = os.path.join('/kaggle/working', 'Autogluon.zip')\n",
    "# with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "#             # Extract all contents into the same directory\n",
    "#             zip_ref.extractall('/kaggle/working/Autogluon')\n",
    "\n",
    "# predict_prof = TabularPredictor.load (path = '/kaggle/working/Autogluon/professional_best')\n",
    "\n",
    "# predict_student = TabularPredictor.load (path = '/kaggle/working/Autogluon/student_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d62fb78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T05:05:36.097419Z",
     "iopub.status.busy": "2024-11-10T05:05:36.096372Z",
     "iopub.status.idle": "2024-11-10T05:05:37.518044Z",
     "shell.execute_reply": "2024-11-10T05:05:37.516922Z"
    },
    "papermill": {
     "duration": 1.545512,
     "end_time": "2024-11-10T05:05:37.522619",
     "exception": false,
     "start_time": "2024-11-10T05:05:35.977107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                          model  score_val eval_metric  pred_time_val      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           WeightedEnsemble_L3   0.973491     roc_auc     210.295007  12058.877057                0.021506          12.285523            3       True         52\n",
      "1           WeightedEnsemble_L2   0.973412     roc_auc      77.108719   5516.504100                0.019851          12.229677            2       True         30\n",
      "2            CatBoost_r9_BAG_L2   0.973255     roc_auc     194.826729  10569.962474                0.724828         223.225686            2       True         46\n",
      "3               CatBoost_BAG_L2   0.973197     roc_auc     194.502868  10599.853387                0.400968         253.116598            2       True         35\n",
      "4          CatBoost_r177_BAG_L2   0.973075     roc_auc     194.421249  10522.767699                0.319349         176.030911            2       True         42\n",
      "5          CatBoost_r137_BAG_L1   0.973074     roc_auc       1.119452   1395.489419                1.119452        1395.489419            1       True         23\n",
      "6          CatBoost_r177_BAG_L1   0.972967     roc_auc       1.232126    632.435266                1.232126         632.435266            1       True         14\n",
      "7               CatBoost_BAG_L1   0.972932     roc_auc       1.523285   1208.175760                1.523285        1208.175760            1       True          7\n",
      "8                XGBoost_BAG_L2   0.972881     roc_auc     195.630831  10500.748961                1.528930         154.012173            2       True         39\n",
      "9           CatBoost_r13_BAG_L1   0.972770     roc_auc       2.411196   1246.323385                2.411196        1246.323385            1       True         25\n",
      "10           XGBoost_r33_BAG_L2   0.972654     roc_auc     201.764905  10697.921250                7.663005         351.184461            2       True         49\n",
      "11          LightGBM_r96_BAG_L2   0.972523     roc_auc     202.588935  10491.057350                8.487035         144.320561            2       True         47\n",
      "12          LightGBM_r96_BAG_L1   0.972261     roc_auc      39.232410    199.337580               39.232410         199.337580            1       True         19\n",
      "13            LightGBMXT_BAG_L2   0.972003     roc_auc     197.080118  10423.110568                2.978218          76.373780            2       True         31\n",
      "14         LightGBM_r131_BAG_L2   0.971957     roc_auc     202.962849  10562.204233                8.860948         215.467444            2       True         44\n",
      "15           XGBoost_r33_BAG_L1   0.971712     roc_auc      19.676121    817.588966               19.676121         817.588966            1       True         21\n",
      "16         LightGBM_r188_BAG_L1   0.971702     roc_auc      12.708797     92.199197               12.708797          92.199197            1       True         27\n",
      "17           CatBoost_r9_BAG_L1   0.971551     roc_auc       1.275652    312.782280                1.275652         312.782280            1       True         18\n",
      "18              LightGBM_BAG_L2   0.971538     roc_auc     196.346342  10429.306627                2.244441          82.569839            2       True         32\n",
      "19        NeuralNetTorch_BAG_L2   0.971500     roc_auc     196.604609  10727.094430                2.502708         380.357642            2       True         40\n",
      "20         LightGBMLarge_BAG_L2   0.971458     roc_auc     197.436827  10477.290853                3.334926         130.554065            2       True         41\n",
      "21               XGBoost_BAG_L1   0.971452     roc_auc       2.066220    262.351545                2.066220         262.351545            1       True         11\n",
      "22            LightGBMXT_BAG_L1   0.971283     roc_auc       7.257834     65.948411                7.257834          65.948411            1       True          3\n",
      "23    NeuralNetTorch_r79_BAG_L2   0.971164     roc_auc     197.485825  10800.875383                3.383925         454.138595            2       True         43\n",
      "24         LightGBM_r131_BAG_L1   0.971015     roc_auc      42.254515    209.485929               42.254515         209.485929            1       True         16\n",
      "25  NeuralNetFastAI_r191_BAG_L2   0.970792     roc_auc     200.510196  11513.176188                6.408295        1166.439399            2       True         45\n",
      "26    NeuralNetTorch_r22_BAG_L2   0.970609     roc_auc     198.180766  10950.563735                4.078866         603.826947            2       True         48\n",
      "27  NeuralNetFastAI_r191_BAG_L1   0.970560     roc_auc       5.999928   1370.679767                5.999928        1370.679767            1       True         17\n",
      "28         CatBoost_r137_BAG_L2   0.970411     roc_auc     194.387668  10362.714609                0.285767          15.977821            2       True         51\n",
      "29    NeuralNetTorch_r22_BAG_L1   0.969887     roc_auc       2.016725    608.231962                2.016725         608.231962            1       True         20\n",
      "30              LightGBM_BAG_L1   0.969627     roc_auc       5.056430     58.073899                5.056430          58.073899            1       True          4\n",
      "31    NeuralNetTorch_r79_BAG_L1   0.969464     roc_auc       1.375294    481.508254                1.375294         481.508254            1       True         15\n",
      "32        NeuralNetTorch_BAG_L1   0.969436     roc_auc       1.197840    417.861097                1.197840         417.861097            1       True         12\n",
      "33         LightGBMLarge_BAG_L1   0.969263     roc_auc       7.358462     86.391855                7.358462          86.391855            1       True         13\n",
      "34       NeuralNetFastAI_BAG_L2   0.969233     roc_auc     197.592956  10795.774817                3.491056         449.038029            2       True         38\n",
      "35        ExtraTreesGini_BAG_L2   0.968863     roc_auc     200.303689  10363.829160                6.201789          17.092371            2       True         36\n",
      "36        ExtraTreesEntr_BAG_L2   0.968664     roc_auc     200.048853  10363.372101                5.946953          16.635312            2       True         37\n",
      "37       NeuralNetFastAI_BAG_L1   0.968571     roc_auc       3.931895    462.238598                3.931895         462.238598            1       True         10\n",
      "38      RandomForestEntr_BAG_L2   0.968334     roc_auc     199.622892  10429.672302                5.520992          82.935514            2       True         34\n",
      "39  NeuralNetFastAI_r145_BAG_L1   0.967542     roc_auc       9.068841    100.862546                9.068841         100.862546            1       True         28\n",
      "40  NeuralNetFastAI_r102_BAG_L1   0.967321     roc_auc       1.199779    152.813708                1.199779         152.813708            1       True         24\n",
      "41           XGBoost_r89_BAG_L1   0.967279     roc_auc       0.856686     35.798707                0.856686          35.798707            1       True         29\n",
      "42        ExtraTrees_r42_BAG_L2   0.967226     roc_auc     199.930737  10399.860253                5.828837          53.123465            2       True         50\n",
      "43      RandomForestGini_BAG_L2   0.967220     roc_auc     199.724445  10428.496097                5.622545          81.759309            2       True         33\n",
      "44        ExtraTreesEntr_BAG_L1   0.966135     roc_auc       4.169197     10.894695                4.169197          10.894695            1       True          9\n",
      "45        ExtraTreesGini_BAG_L1   0.965886     roc_auc       4.173709     11.342101                4.173709          11.342101            1       True          8\n",
      "46      RandomForestGini_BAG_L1   0.965812     roc_auc       3.880210     18.272864                3.880210          18.272864            1       True          5\n",
      "47      RandomForestEntr_BAG_L1   0.965760     roc_auc       3.833807     17.231498                3.833807          17.231498            1       True          6\n",
      "48        ExtraTrees_r42_BAG_L1   0.964423     roc_auc       3.753604     20.784894                3.753604          20.784894            1       True         22\n",
      "49     RandomForest_r195_BAG_L1   0.960257     roc_auc       3.525875     51.342314                3.525875          51.342314            1       True         26\n",
      "50        KNeighborsUnif_BAG_L1   0.888826     roc_auc       0.975276      0.154150                0.975276           0.154150            1       True          1\n",
      "51        KNeighborsDist_BAG_L1   0.840174     roc_auc       0.970732      0.136140                0.970732           0.136140            1       True          2\n",
      "Number of models trained: 52\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XT', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_TabularNeuralNetTorch', 'WeightedEnsembleModel', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_CatBoost'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "('float', [])     : 5 | ['Age', 'Work Pressure', 'Job Satisfaction', 'Work/Study Hours', 'Financial Stress']\n",
      "('int', ['bool']) : 3 | ['Gender', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "Plot summary of models saved to file: /kaggle/working/Autogluon/professional_bestSummaryOfModels.html\n",
      "*** End of fit() summary ***\n",
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                           model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0            WeightedEnsemble_L2   0.924024     roc_auc       3.762056  990.430052                0.005348           3.073328            2       True        111\n",
      "1             CatBoost_r5_BAG_L1   0.923557     roc_auc       0.275741  156.568539                0.275741         156.568539            1       True         71\n",
      "2           CatBoost_r177_BAG_L1   0.923550     roc_auc       0.260989   95.237888                0.260989          95.237888            1       True         14\n",
      "3            CatBoost_r12_BAG_L1   0.923301     roc_auc       0.402268  206.513529                0.402268         206.513529            1       True         96\n",
      "4           CatBoost_r137_BAG_L1   0.923216     roc_auc       0.293047  180.528021                0.293047         180.528021            1       True         23\n",
      "5            CatBoost_r69_BAG_L1   0.923161     roc_auc       0.309744  151.415995                0.309744         151.415995            1       True         37\n",
      "6           CatBoost_r198_BAG_L1   0.923107     roc_auc       0.414057  202.807345                0.414057         202.807345            1       True        103\n",
      "7           CatBoost_r143_BAG_L1   0.923100     roc_auc       0.212576   78.280607                0.212576          78.280607            1       True         74\n",
      "8            CatBoost_r13_BAG_L1   0.923090     roc_auc       0.568178  334.702219                0.568178         334.702219            1       True         25\n",
      "9            CatBoost_r60_BAG_L1   0.923025     roc_auc       0.295376  127.734530                0.295376         127.734530            1       True         80\n",
      "10               CatBoost_BAG_L1   0.922970     roc_auc       0.273734  169.084654                0.273734         169.084654            1       True          7\n",
      "11          CatBoost_r167_BAG_L1   0.922741     roc_auc       0.250371   98.762261                0.250371          98.762261            1       True         46\n",
      "12           CatBoost_r86_BAG_L1   0.922602     roc_auc       0.362205  203.687801                0.362205         203.687801            1       True         52\n",
      "13           CatBoost_r49_BAG_L1   0.922407     roc_auc       0.141587   55.065809                0.141587          55.065809            1       True         55\n",
      "14            CatBoost_r6_BAG_L1   0.922182     roc_auc       0.222242   46.643547                0.222242          46.643547            1       True         85\n",
      "15          CatBoost_r163_BAG_L1   0.922161     roc_auc       0.126216   42.812658                0.126216          42.812658            1       True        102\n",
      "16           CatBoost_r50_BAG_L1   0.921904     roc_auc       0.246158   51.899083                0.246158          51.899083            1       True         33\n",
      "17           CatBoost_r70_BAG_L1   0.921816     roc_auc       0.320332   70.349066                0.320332          70.349066            1       True         42\n",
      "18            XGBoost_r31_BAG_L1   0.921734     roc_auc       3.244607  152.808637                3.244607         152.808637            1       True         77\n",
      "19            CatBoost_r9_BAG_L1   0.921247     roc_auc       0.420877  100.736985                0.420877         100.736985            1       True         18\n",
      "20          CatBoost_r180_BAG_L1   0.921074     roc_auc       0.289730   59.596499                0.289730          59.596499            1       True         89\n",
      "21            XGBoost_r89_BAG_L1   0.921054     roc_auc       0.462448   28.390939                0.462448          28.390939            1       True         29\n",
      "22          CatBoost_r128_BAG_L1   0.921002     roc_auc       0.331944   81.977063                0.331944          81.977063            1       True         63\n",
      "23           LightGBM_r96_BAG_L1   0.920979     roc_auc      10.081615   61.561791               10.081615          61.561791            1       True         19\n",
      "24          LightGBM_r196_BAG_L1   0.920855     roc_auc      89.243544  194.884504               89.243544         194.884504            1       True         44\n",
      "25   NeuralNetFastAI_r187_BAG_L1   0.920753     roc_auc       0.623844   66.985349                0.623844          66.985349            1       True        104\n",
      "26           LightGBM_r94_BAG_L1   0.920736     roc_auc       4.072877   29.697325                4.072877          29.697325            1       True         61\n",
      "27            XGBoost_r22_BAG_L1   0.920606     roc_auc       0.535115   30.174252                0.535115          30.174252            1       True         83\n",
      "28            XGBoost_r95_BAG_L1   0.920605     roc_auc       0.510797   31.743758                0.510797          31.743758            1       True        106\n",
      "29    NeuralNetFastAI_r65_BAG_L1   0.920577     roc_auc       0.512335   75.610255                0.512335          75.610255            1       True         67\n",
      "30    NeuralNetTorch_r121_BAG_L1   0.920392     roc_auc       2.163819  660.605917                2.163819         660.605917            1       True         92\n",
      "31     NeuralNetTorch_r36_BAG_L1   0.920235     roc_auc       0.407521   93.298095                0.407521          93.298095            1       True        100\n",
      "32    NeuralNetTorch_r143_BAG_L1   0.920233     roc_auc       0.808820  231.859741                0.808820         231.859741            1       True         62\n",
      "33             LightGBMXT_BAG_L1   0.920220     roc_auc       1.816924   25.764438                1.816924          25.764438            1       True          3\n",
      "34     NeuralNetTorch_r31_BAG_L1   0.920178     roc_auc       0.408234  109.236298                0.408234         109.236298            1       True         65\n",
      "35    NeuralNetFastAI_r37_BAG_L1   0.920098     roc_auc       1.154828  100.989464                1.154828         100.989464            1       True         53\n",
      "36   NeuralNetFastAI_r143_BAG_L1   0.919984     roc_auc       0.558606   79.282488                0.558606          79.282488            1       True         41\n",
      "37           LightGBM_r30_BAG_L1   0.919924     roc_auc      17.913014   88.595653               17.913014          88.595653            1       True         69\n",
      "38            XGBoost_r49_BAG_L1   0.919853     roc_auc       0.903047   38.460179                0.903047          38.460179            1       True         70\n",
      "39     NeuralNetTorch_r79_BAG_L1   0.919847     roc_auc       0.450166  130.704647                0.450166         130.704647            1       True         15\n",
      "40           LightGBM_r42_BAG_L1   0.919837     roc_auc       2.405453   25.385581                2.405453          25.385581            1       True        108\n",
      "41     NeuralNetFastAI_r4_BAG_L1   0.919685     roc_auc       1.042051  108.658241                1.042051         108.658241            1       True         98\n",
      "42          LightGBM_r188_BAG_L1   0.919493     roc_auc       3.663979   37.767454                3.663979          37.767454            1       True         27\n",
      "43                XGBoost_BAG_L1   0.919481     roc_auc       0.502878   26.199342                0.502878          26.199342            1       True         11\n",
      "44   NeuralNetFastAI_r100_BAG_L1   0.919421     roc_auc       1.030827  203.296706                1.030827         203.296706            1       True        101\n",
      "45   NeuralNetFastAI_r111_BAG_L1   0.919219     roc_auc       0.862960   60.666312                0.862960          60.666312            1       True         64\n",
      "46            XGBoost_r34_BAG_L1   0.919156     roc_auc       2.326841   49.312991                2.326841          49.312991            1       True        107\n",
      "47    NeuralNetFastAI_r95_BAG_L1   0.919040     roc_auc       1.837760  304.211688                1.837760         304.211688            1       True         47\n",
      "48   NeuralNetFastAI_r156_BAG_L1   0.919036     roc_auc       0.493853   51.195819                0.493853          51.195819            1       True         43\n",
      "49     NeuralNetTorch_r22_BAG_L1   0.919020     roc_auc       0.662064  158.511546                0.662064         158.511546            1       True         20\n",
      "50   NeuralNetFastAI_r160_BAG_L1   0.918649     roc_auc       2.310726  211.894302                2.310726         211.894302            1       True         79\n",
      "51     NeuralNetTorch_r14_BAG_L1   0.918604     roc_auc       0.301934   62.628945                0.301934          62.628945            1       True         39\n",
      "52            XGBoost_r33_BAG_L1   0.918498     roc_auc       3.804348   63.025320                3.804348          63.025320            1       True         21\n",
      "53          LightGBM_r121_BAG_L1   0.918366     roc_auc      21.806472   87.217348               21.806472          87.217348            1       True         87\n",
      "54          LightGBM_r161_BAG_L1   0.918362     roc_auc      22.457226   86.953406               22.457226          86.953406            1       True         40\n",
      "55           LightGBM_r15_BAG_L1   0.918309     roc_auc       3.998126   42.456688                3.998126          42.456688            1       True         50\n",
      "56        NeuralNetFastAI_BAG_L1   0.918190     roc_auc       0.971544  116.787980                0.971544         116.787980            1       True         10\n",
      "57      NeuralNetTorch_r1_BAG_L1   0.918188     roc_auc       0.540907  143.936411                0.540907         143.936411            1       True        109\n",
      "58   NeuralNetFastAI_r194_BAG_L1   0.918171     roc_auc       1.314931  141.294279                1.314931         141.294279            1       True         95\n",
      "59     NeuralNetTorch_r76_BAG_L1   0.918154     roc_auc       0.311146   65.989243                0.311146          65.989243            1       True         90\n",
      "60     NeuralNetTorch_r19_BAG_L1   0.918151     roc_auc       0.286572   64.839960                0.286572          64.839960            1       True        105\n",
      "61     NeuralNetTorch_r89_BAG_L1   0.918063     roc_auc       0.564954  137.215237                0.564954         137.215237            1       True        110\n",
      "62     NeuralNetTorch_r86_BAG_L1   0.918013     roc_auc       0.460635  195.791903                0.460635         195.791903            1       True         32\n",
      "63    NeuralNetTorch_r135_BAG_L1   0.917932     roc_auc       0.537199  148.789162                0.537199         148.789162            1       True         97\n",
      "64         NeuralNetTorch_BAG_L1   0.917833     roc_auc       0.406540  103.653604                0.406540         103.653604            1       True         12\n",
      "65          LightGBM_r130_BAG_L1   0.917766     roc_auc       1.961250   27.643215                1.961250          27.643215            1       True         31\n",
      "66          LightGBM_r131_BAG_L1   0.917762     roc_auc       9.569795   60.905412                9.569795          60.905412            1       True         16\n",
      "67    NeuralNetFastAI_r69_BAG_L1   0.917749     roc_auc       2.000358  190.569214                2.000358         190.569214            1       True         84\n",
      "68     NeuralNetTorch_r41_BAG_L1   0.917607     roc_auc       0.296836  102.356216                0.296836         102.356216            1       True         48\n",
      "69    NeuralNetTorch_r185_BAG_L1   0.917562     roc_auc       0.517250  127.879146                0.517250         127.879146            1       True         78\n",
      "70     NeuralNetTorch_r30_BAG_L1   0.917501     roc_auc       0.688250  171.245502                0.688250         171.245502            1       True         30\n",
      "71     NeuralNetTorch_r87_BAG_L1   0.917350     roc_auc       0.397546   99.327169                0.397546          99.327169            1       True         72\n",
      "72            XGBoost_r98_BAG_L1   0.917086     roc_auc       7.454616   97.159504                7.454616          97.159504            1       True         49\n",
      "73   NeuralNetFastAI_r191_BAG_L1   0.916853     roc_auc       1.566633  278.594239                1.566633         278.594239            1       True         17\n",
      "74   NeuralNetFastAI_r145_BAG_L1   0.916826     roc_auc       2.251317  282.575931                2.251317         282.575931            1       True         28\n",
      "75   NeuralNetFastAI_r138_BAG_L1   0.916815     roc_auc       2.401505  342.479480                2.401505         342.479480            1       True         86\n",
      "76        ExtraTrees_r126_BAG_L1   0.916429     roc_auc       1.219776    3.548958                1.219776           3.548958            1       True         99\n",
      "77          LightGBM_r135_BAG_L1   0.916295     roc_auc       2.570745   40.016719                2.570745          40.016719            1       True         82\n",
      "78    NeuralNetFastAI_r88_BAG_L1   0.916155     roc_auc       0.634023   74.943782                0.634023          74.943782            1       True         68\n",
      "79               LightGBM_BAG_L1   0.916076     roc_auc       1.705569   27.526606                1.705569          27.526606            1       True          4\n",
      "80   NeuralNetFastAI_r103_BAG_L1   0.915672     roc_auc       1.086738  145.333427                1.086738         145.333427            1       True         38\n",
      "81   NeuralNetFastAI_r134_BAG_L1   0.915619     roc_auc       1.041544  143.577493                1.041544         143.577493            1       True         59\n",
      "82          ExtraTrees_r4_BAG_L1   0.915547     roc_auc       1.027083    5.079173                1.027083           5.079173            1       True         66\n",
      "83          LightGBM_r143_BAG_L1   0.915494     roc_auc       6.525262   62.884132                6.525262          62.884132            1       True         57\n",
      "84   NeuralNetFastAI_r102_BAG_L1   0.915384     roc_auc       0.517408   44.785979                0.517408          44.785979            1       True         24\n",
      "85     NeuralNetTorch_r71_BAG_L1   0.915371     roc_auc       0.349290   58.539950                0.349290          58.539950            1       True         73\n",
      "86          LightGBMLarge_BAG_L1   0.915335     roc_auc       2.634795   38.925817                2.634795          38.925817            1       True         13\n",
      "87       RandomForestEntr_BAG_L1   0.915282     roc_auc       1.254477    5.769713                1.254477           5.769713            1       True          6\n",
      "88       RandomForest_r34_BAG_L1   0.915074     roc_auc       0.960277    7.889753                0.960277           7.889753            1       True         60\n",
      "89    NeuralNetTorch_r197_BAG_L1   0.915068     roc_auc       0.437892   64.006665                0.437892          64.006665            1       True         54\n",
      "90        ExtraTrees_r178_BAG_L1   0.914953     roc_auc       1.157587    5.210810                1.157587           5.210810            1       True         75\n",
      "91         ExtraTreesGini_BAG_L1   0.914709     roc_auc       1.368297    3.810887                1.368297           3.810887            1       True          8\n",
      "92         ExtraTrees_r49_BAG_L1   0.914709     roc_auc       1.369342    4.021100                1.369342           4.021100            1       True         56\n",
      "93         ExtraTreesEntr_BAG_L1   0.914700     roc_auc       1.348849    3.845751                1.348849           3.845751            1       True          9\n",
      "94      RandomForest_r166_BAG_L1   0.914411     roc_auc       1.248251    5.578960                1.248251           5.578960            1       True         76\n",
      "95       RandomForestGini_BAG_L1   0.914411     roc_auc       1.260401    5.676186                1.260401           5.676186            1       True          5\n",
      "96        ExtraTrees_r172_BAG_L1   0.914258     roc_auc       1.142550    5.729816                1.142550           5.729816            1       True         36\n",
      "97   NeuralNetFastAI_r172_BAG_L1   0.914071     roc_auc       0.765789   72.385381                0.765789          72.385381            1       True         88\n",
      "98    NeuralNetFastAI_r11_BAG_L1   0.913998     roc_auc       2.262449  347.419044                2.262449         347.419044            1       True         34\n",
      "99   NeuralNetFastAI_r127_BAG_L1   0.913926     roc_auc       0.759316   57.105770                0.759316          57.105770            1       True         93\n",
      "100     RandomForest_r127_BAG_L1   0.912020     roc_auc       1.095344   13.949154                1.095344          13.949154            1       True         58\n",
      "101      RandomForest_r15_BAG_L1   0.911637     roc_auc       1.123371   11.070875                1.123371          11.070875            1       True         81\n",
      "102      RandomForest_r39_BAG_L1   0.910908     roc_auc       1.169551   11.967261                1.169551          11.967261            1       True         45\n",
      "103        ExtraTrees_r42_BAG_L1   0.910857     roc_auc       1.313149    5.798694                1.313149           5.798694            1       True         22\n",
      "104          XGBoost_r194_BAG_L1   0.910813     roc_auc       0.364635   16.241988                0.364635          16.241988            1       True         35\n",
      "105       ExtraTrees_r197_BAG_L1   0.910497     roc_auc       1.210981    7.207674                1.210981           7.207674            1       True         91\n",
      "106     RandomForest_r195_BAG_L1   0.908968     roc_auc       1.216158   12.144714                1.216158          12.144714            1       True         26\n",
      "107      RandomForest_r16_BAG_L1   0.907693     roc_auc       1.175329   16.974463                1.175329          16.974463            1       True         94\n",
      "108   NeuralNetTorch_r158_BAG_L1   0.905820     roc_auc       0.677258  323.839453                0.677258         323.839453            1       True         51\n",
      "109        KNeighborsUnif_BAG_L1   0.813516     roc_auc       0.251116    0.442622                0.251116           0.442622            1       True          1\n",
      "110        KNeighborsDist_BAG_L1   0.807168     roc_auc       0.252986    0.039287                0.252986           0.039287            1       True          2\n",
      "Number of models trained: 111\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XT', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_TabularNeuralNetTorch', 'WeightedEnsembleModel', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_CatBoost'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 5 | ['Name', 'City', 'Sleep Duration', 'Dietary Habits', 'Degree']\n",
      "('float', [])     : 6 | ['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', ...]\n",
      "('int', ['bool']) : 3 | ['Gender', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "Plot summary of models saved to file: /kaggle/working/Autogluon/student_mediumSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestGini_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'RandomForestEntr_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesGini_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'ExtraTreesEntr_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetTorch_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetTorch_r79_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'LightGBM_r131_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetTorch_r22_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'XGBoost_r33_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'ExtraTrees_r42_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'CatBoost_r137_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'RandomForest_r195_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'LightGBM_r188_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r89_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetTorch_r30_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'LightGBM_r130_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetTorch_r86_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'CatBoost_r50_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r194_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'ExtraTrees_r172_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'CatBoost_r69_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetTorch_r14_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'LightGBM_r161_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r70_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r196_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForest_r39_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_r167_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetTorch_r41_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'XGBoost_r98_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r15_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetTorch_r158_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'CatBoost_r86_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetTorch_r197_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'CatBoost_r49_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTrees_r49_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'LightGBM_r143_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForest_r127_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'RandomForest_r34_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'LightGBM_r94_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetTorch_r143_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'CatBoost_r128_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetTorch_r31_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'ExtraTrees_r4_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r30_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r49_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r5_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetTorch_r87_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'NeuralNetTorch_r71_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'CatBoost_r143_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTrees_r178_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'RandomForest_r166_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'XGBoost_r31_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetTorch_r185_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r60_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'RandomForest_r15_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'LightGBM_r135_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r22_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r6_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r121_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r180_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetTorch_r76_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'ExtraTrees_r197_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetTorch_r121_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'RandomForest_r16_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r12_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetTorch_r135_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'ExtraTrees_r126_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetTorch_r36_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r163_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r198_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetTorch_r19_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'XGBoost_r95_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'XGBoost_r34_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r42_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetTorch_r1_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'NeuralNetTorch_r89_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.8135164358671106,\n",
       "  'KNeighborsDist_BAG_L1': 0.8071683365282376,\n",
       "  'LightGBMXT_BAG_L1': 0.9202204314666538,\n",
       "  'LightGBM_BAG_L1': 0.9160763450886338,\n",
       "  'RandomForestGini_BAG_L1': 0.9144105883027964,\n",
       "  'RandomForestEntr_BAG_L1': 0.9152821869152468,\n",
       "  'CatBoost_BAG_L1': 0.9229704232094456,\n",
       "  'ExtraTreesGini_BAG_L1': 0.914708726450548,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.914700151657391,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.918190031601818,\n",
       "  'XGBoost_BAG_L1': 0.9194811255040604,\n",
       "  'NeuralNetTorch_BAG_L1': 0.9178326638642971,\n",
       "  'LightGBMLarge_BAG_L1': 0.9153354803133333,\n",
       "  'CatBoost_r177_BAG_L1': 0.9235499310205528,\n",
       "  'NeuralNetTorch_r79_BAG_L1': 0.9198465598988472,\n",
       "  'LightGBM_r131_BAG_L1': 0.9177623611465748,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.9168527555574187,\n",
       "  'CatBoost_r9_BAG_L1': 0.9212472841195254,\n",
       "  'LightGBM_r96_BAG_L1': 0.9209787210685421,\n",
       "  'NeuralNetTorch_r22_BAG_L1': 0.9190197910460528,\n",
       "  'XGBoost_r33_BAG_L1': 0.9184979804774189,\n",
       "  'ExtraTrees_r42_BAG_L1': 0.9108568764336313,\n",
       "  'CatBoost_r137_BAG_L1': 0.923215670233357,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.9153837532229578,\n",
       "  'CatBoost_r13_BAG_L1': 0.9230904994255946,\n",
       "  'RandomForest_r195_BAG_L1': 0.9089683602835906,\n",
       "  'LightGBM_r188_BAG_L1': 0.919493132861021,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.916825842880995,\n",
       "  'XGBoost_r89_BAG_L1': 0.92105390665459,\n",
       "  'NeuralNetTorch_r30_BAG_L1': 0.9175005705942607,\n",
       "  'LightGBM_r130_BAG_L1': 0.9177659869078787,\n",
       "  'NeuralNetTorch_r86_BAG_L1': 0.9180134279143605,\n",
       "  'CatBoost_r50_BAG_L1': 0.9219040603445245,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 0.9139981486915713,\n",
       "  'XGBoost_r194_BAG_L1': 0.9108130444199692,\n",
       "  'ExtraTrees_r172_BAG_L1': 0.9142584862928227,\n",
       "  'CatBoost_r69_BAG_L1': 0.9231612414691394,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 0.91567157515351,\n",
       "  'NeuralNetTorch_r14_BAG_L1': 0.9186039373968113,\n",
       "  'LightGBM_r161_BAG_L1': 0.9183620488335529,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 0.9199842567856256,\n",
       "  'CatBoost_r70_BAG_L1': 0.9218163804379539,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 0.9190362234197291,\n",
       "  'LightGBM_r196_BAG_L1': 0.9208551037804039,\n",
       "  'RandomForest_r39_BAG_L1': 0.9109084257611346,\n",
       "  'CatBoost_r167_BAG_L1': 0.9227409125189017,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 0.9190397591986359,\n",
       "  'NeuralNetTorch_r41_BAG_L1': 0.9176070753476604,\n",
       "  'XGBoost_r98_BAG_L1': 0.9170857199840954,\n",
       "  'LightGBM_r15_BAG_L1': 0.9183092953298501,\n",
       "  'NeuralNetTorch_r158_BAG_L1': 0.9058202784754059,\n",
       "  'CatBoost_r86_BAG_L1': 0.9226016330005467,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 0.9200978542691672,\n",
       "  'NeuralNetTorch_r197_BAG_L1': 0.9150677879743713,\n",
       "  'CatBoost_r49_BAG_L1': 0.9224074245217064,\n",
       "  'ExtraTrees_r49_BAG_L1': 0.914708726450548,\n",
       "  'LightGBM_r143_BAG_L1': 0.915493523808072,\n",
       "  'RandomForest_r127_BAG_L1': 0.9120197533593075,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 0.9156192292171361,\n",
       "  'RandomForest_r34_BAG_L1': 0.9150741026214306,\n",
       "  'LightGBM_r94_BAG_L1': 0.920735840052372,\n",
       "  'NeuralNetTorch_r143_BAG_L1': 0.920232907261389,\n",
       "  'CatBoost_r128_BAG_L1': 0.9210015316062641,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 0.9192185568686634,\n",
       "  'NeuralNetTorch_r31_BAG_L1': 0.9201778644996365,\n",
       "  'ExtraTrees_r4_BAG_L1': 0.9155468727835219,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 0.9205770370003383,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 0.916155354926568,\n",
       "  'LightGBM_r30_BAG_L1': 0.9199237859680814,\n",
       "  'XGBoost_r49_BAG_L1': 0.9198528798389887,\n",
       "  'CatBoost_r5_BAG_L1': 0.9235572222412773,\n",
       "  'NeuralNetTorch_r87_BAG_L1': 0.9173497230447673,\n",
       "  'NeuralNetTorch_r71_BAG_L1': 0.9153713594709967,\n",
       "  'CatBoost_r143_BAG_L1': 0.9230998258364235,\n",
       "  'ExtraTrees_r178_BAG_L1': 0.9149532483221988,\n",
       "  'RandomForest_r166_BAG_L1': 0.9144105883027964,\n",
       "  'XGBoost_r31_BAG_L1': 0.9217338401141951,\n",
       "  'NeuralNetTorch_r185_BAG_L1': 0.9175616368835519,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 0.9186487115791042,\n",
       "  'CatBoost_r60_BAG_L1': 0.9230245979057179,\n",
       "  'RandomForest_r15_BAG_L1': 0.9116368941379327,\n",
       "  'LightGBM_r135_BAG_L1': 0.9162954945707796,\n",
       "  'XGBoost_r22_BAG_L1': 0.9206060139788184,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 0.9177492051907774,\n",
       "  'CatBoost_r6_BAG_L1': 0.9221818704101038,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 0.9168152434838982,\n",
       "  'LightGBM_r121_BAG_L1': 0.918365785749583,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 0.9140707988912474,\n",
       "  'CatBoost_r180_BAG_L1': 0.9210738880398786,\n",
       "  'NeuralNetTorch_r76_BAG_L1': 0.9181537713422367,\n",
       "  'ExtraTrees_r197_BAG_L1': 0.9104969680166566,\n",
       "  'NeuralNetTorch_r121_BAG_L1': 0.9203915462278744,\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 0.9139258584214842,\n",
       "  'RandomForest_r16_BAG_L1': 0.9076931641537231,\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 0.9181714793487221,\n",
       "  'CatBoost_r12_BAG_L1': 0.9233013361221525,\n",
       "  'NeuralNetTorch_r135_BAG_L1': 0.917931898569301,\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 0.9196852002881131,\n",
       "  'ExtraTrees_r126_BAG_L1': 0.9164294651276923,\n",
       "  'NeuralNetTorch_r36_BAG_L1': 0.9202354744062539,\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 0.9194211575293246,\n",
       "  'CatBoost_r163_BAG_L1': 0.9221608145291296,\n",
       "  'CatBoost_r198_BAG_L1': 0.9231072493842029,\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 0.9207525556059457,\n",
       "  'NeuralNetTorch_r19_BAG_L1': 0.9181513629898377,\n",
       "  'XGBoost_r95_BAG_L1': 0.9206053549900851,\n",
       "  'XGBoost_r34_BAG_L1': 0.9191557729741997,\n",
       "  'LightGBM_r42_BAG_L1': 0.9198365400942506,\n",
       "  'NeuralNetTorch_r1_BAG_L1': 0.918188438384077,\n",
       "  'NeuralNetTorch_r89_BAG_L1': 0.918063008215287,\n",
       "  'WeightedEnsemble_L2': 0.9240236195324049},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': ['KNeighborsUnif_BAG_L1'],\n",
       "  'KNeighborsDist_BAG_L1': ['KNeighborsDist_BAG_L1'],\n",
       "  'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'RandomForestGini_BAG_L1': ['RandomForestGini_BAG_L1'],\n",
       "  'RandomForestEntr_BAG_L1': ['RandomForestEntr_BAG_L1'],\n",
       "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
       "  'ExtraTreesGini_BAG_L1': ['ExtraTreesGini_BAG_L1'],\n",
       "  'ExtraTreesEntr_BAG_L1': ['ExtraTreesEntr_BAG_L1'],\n",
       "  'NeuralNetFastAI_BAG_L1': ['NeuralNetFastAI_BAG_L1'],\n",
       "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
       "  'NeuralNetTorch_BAG_L1': ['NeuralNetTorch_BAG_L1'],\n",
       "  'LightGBMLarge_BAG_L1': ['LightGBMLarge_BAG_L1'],\n",
       "  'CatBoost_r177_BAG_L1': ['CatBoost_r177_BAG_L1'],\n",
       "  'NeuralNetTorch_r79_BAG_L1': ['NeuralNetTorch_r79_BAG_L1'],\n",
       "  'LightGBM_r131_BAG_L1': ['LightGBM_r131_BAG_L1'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1': ['NeuralNetFastAI_r191_BAG_L1'],\n",
       "  'CatBoost_r9_BAG_L1': ['CatBoost_r9_BAG_L1'],\n",
       "  'LightGBM_r96_BAG_L1': ['LightGBM_r96_BAG_L1'],\n",
       "  'NeuralNetTorch_r22_BAG_L1': ['NeuralNetTorch_r22_BAG_L1'],\n",
       "  'XGBoost_r33_BAG_L1': ['XGBoost_r33_BAG_L1'],\n",
       "  'ExtraTrees_r42_BAG_L1': ['ExtraTrees_r42_BAG_L1'],\n",
       "  'CatBoost_r137_BAG_L1': ['CatBoost_r137_BAG_L1'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1': ['NeuralNetFastAI_r102_BAG_L1'],\n",
       "  'CatBoost_r13_BAG_L1': ['CatBoost_r13_BAG_L1'],\n",
       "  'RandomForest_r195_BAG_L1': ['RandomForest_r195_BAG_L1'],\n",
       "  'LightGBM_r188_BAG_L1': ['LightGBM_r188_BAG_L1'],\n",
       "  'NeuralNetFastAI_r145_BAG_L1': ['NeuralNetFastAI_r145_BAG_L1'],\n",
       "  'XGBoost_r89_BAG_L1': ['XGBoost_r89_BAG_L1'],\n",
       "  'NeuralNetTorch_r30_BAG_L1': ['NeuralNetTorch_r30_BAG_L1'],\n",
       "  'LightGBM_r130_BAG_L1': ['LightGBM_r130_BAG_L1'],\n",
       "  'NeuralNetTorch_r86_BAG_L1': ['NeuralNetTorch_r86_BAG_L1'],\n",
       "  'CatBoost_r50_BAG_L1': ['CatBoost_r50_BAG_L1'],\n",
       "  'NeuralNetFastAI_r11_BAG_L1': ['NeuralNetFastAI_r11_BAG_L1'],\n",
       "  'XGBoost_r194_BAG_L1': ['XGBoost_r194_BAG_L1'],\n",
       "  'ExtraTrees_r172_BAG_L1': ['ExtraTrees_r172_BAG_L1'],\n",
       "  'CatBoost_r69_BAG_L1': ['CatBoost_r69_BAG_L1'],\n",
       "  'NeuralNetFastAI_r103_BAG_L1': ['NeuralNetFastAI_r103_BAG_L1'],\n",
       "  'NeuralNetTorch_r14_BAG_L1': ['NeuralNetTorch_r14_BAG_L1'],\n",
       "  'LightGBM_r161_BAG_L1': ['LightGBM_r161_BAG_L1'],\n",
       "  'NeuralNetFastAI_r143_BAG_L1': ['NeuralNetFastAI_r143_BAG_L1'],\n",
       "  'CatBoost_r70_BAG_L1': ['CatBoost_r70_BAG_L1'],\n",
       "  'NeuralNetFastAI_r156_BAG_L1': ['NeuralNetFastAI_r156_BAG_L1'],\n",
       "  'LightGBM_r196_BAG_L1': ['LightGBM_r196_BAG_L1'],\n",
       "  'RandomForest_r39_BAG_L1': ['RandomForest_r39_BAG_L1'],\n",
       "  'CatBoost_r167_BAG_L1': ['CatBoost_r167_BAG_L1'],\n",
       "  'NeuralNetFastAI_r95_BAG_L1': ['NeuralNetFastAI_r95_BAG_L1'],\n",
       "  'NeuralNetTorch_r41_BAG_L1': ['NeuralNetTorch_r41_BAG_L1'],\n",
       "  'XGBoost_r98_BAG_L1': ['XGBoost_r98_BAG_L1'],\n",
       "  'LightGBM_r15_BAG_L1': ['LightGBM_r15_BAG_L1'],\n",
       "  'NeuralNetTorch_r158_BAG_L1': ['NeuralNetTorch_r158_BAG_L1'],\n",
       "  'CatBoost_r86_BAG_L1': ['CatBoost_r86_BAG_L1'],\n",
       "  'NeuralNetFastAI_r37_BAG_L1': ['NeuralNetFastAI_r37_BAG_L1'],\n",
       "  'NeuralNetTorch_r197_BAG_L1': ['NeuralNetTorch_r197_BAG_L1'],\n",
       "  'CatBoost_r49_BAG_L1': ['CatBoost_r49_BAG_L1'],\n",
       "  'ExtraTrees_r49_BAG_L1': ['ExtraTrees_r49_BAG_L1'],\n",
       "  'LightGBM_r143_BAG_L1': ['LightGBM_r143_BAG_L1'],\n",
       "  'RandomForest_r127_BAG_L1': ['RandomForest_r127_BAG_L1'],\n",
       "  'NeuralNetFastAI_r134_BAG_L1': ['NeuralNetFastAI_r134_BAG_L1'],\n",
       "  'RandomForest_r34_BAG_L1': ['RandomForest_r34_BAG_L1'],\n",
       "  'LightGBM_r94_BAG_L1': ['LightGBM_r94_BAG_L1'],\n",
       "  'NeuralNetTorch_r143_BAG_L1': ['NeuralNetTorch_r143_BAG_L1'],\n",
       "  'CatBoost_r128_BAG_L1': ['CatBoost_r128_BAG_L1'],\n",
       "  'NeuralNetFastAI_r111_BAG_L1': ['NeuralNetFastAI_r111_BAG_L1'],\n",
       "  'NeuralNetTorch_r31_BAG_L1': ['NeuralNetTorch_r31_BAG_L1'],\n",
       "  'ExtraTrees_r4_BAG_L1': ['ExtraTrees_r4_BAG_L1'],\n",
       "  'NeuralNetFastAI_r65_BAG_L1': ['NeuralNetFastAI_r65_BAG_L1'],\n",
       "  'NeuralNetFastAI_r88_BAG_L1': ['NeuralNetFastAI_r88_BAG_L1'],\n",
       "  'LightGBM_r30_BAG_L1': ['LightGBM_r30_BAG_L1'],\n",
       "  'XGBoost_r49_BAG_L1': ['XGBoost_r49_BAG_L1'],\n",
       "  'CatBoost_r5_BAG_L1': ['CatBoost_r5_BAG_L1'],\n",
       "  'NeuralNetTorch_r87_BAG_L1': ['NeuralNetTorch_r87_BAG_L1'],\n",
       "  'NeuralNetTorch_r71_BAG_L1': ['NeuralNetTorch_r71_BAG_L1'],\n",
       "  'CatBoost_r143_BAG_L1': ['CatBoost_r143_BAG_L1'],\n",
       "  'ExtraTrees_r178_BAG_L1': ['ExtraTrees_r178_BAG_L1'],\n",
       "  'RandomForest_r166_BAG_L1': ['RandomForest_r166_BAG_L1'],\n",
       "  'XGBoost_r31_BAG_L1': ['XGBoost_r31_BAG_L1'],\n",
       "  'NeuralNetTorch_r185_BAG_L1': ['NeuralNetTorch_r185_BAG_L1'],\n",
       "  'NeuralNetFastAI_r160_BAG_L1': ['NeuralNetFastAI_r160_BAG_L1'],\n",
       "  'CatBoost_r60_BAG_L1': ['CatBoost_r60_BAG_L1'],\n",
       "  'RandomForest_r15_BAG_L1': ['RandomForest_r15_BAG_L1'],\n",
       "  'LightGBM_r135_BAG_L1': ['LightGBM_r135_BAG_L1'],\n",
       "  'XGBoost_r22_BAG_L1': ['XGBoost_r22_BAG_L1'],\n",
       "  'NeuralNetFastAI_r69_BAG_L1': ['NeuralNetFastAI_r69_BAG_L1'],\n",
       "  'CatBoost_r6_BAG_L1': ['CatBoost_r6_BAG_L1'],\n",
       "  'NeuralNetFastAI_r138_BAG_L1': ['NeuralNetFastAI_r138_BAG_L1'],\n",
       "  'LightGBM_r121_BAG_L1': ['LightGBM_r121_BAG_L1'],\n",
       "  'NeuralNetFastAI_r172_BAG_L1': ['NeuralNetFastAI_r172_BAG_L1'],\n",
       "  'CatBoost_r180_BAG_L1': ['CatBoost_r180_BAG_L1'],\n",
       "  'NeuralNetTorch_r76_BAG_L1': ['NeuralNetTorch_r76_BAG_L1'],\n",
       "  'ExtraTrees_r197_BAG_L1': ['ExtraTrees_r197_BAG_L1'],\n",
       "  'NeuralNetTorch_r121_BAG_L1': ['NeuralNetTorch_r121_BAG_L1'],\n",
       "  'NeuralNetFastAI_r127_BAG_L1': ['NeuralNetFastAI_r127_BAG_L1'],\n",
       "  'RandomForest_r16_BAG_L1': ['RandomForest_r16_BAG_L1'],\n",
       "  'NeuralNetFastAI_r194_BAG_L1': ['NeuralNetFastAI_r194_BAG_L1'],\n",
       "  'CatBoost_r12_BAG_L1': ['CatBoost_r12_BAG_L1'],\n",
       "  'NeuralNetTorch_r135_BAG_L1': ['NeuralNetTorch_r135_BAG_L1'],\n",
       "  'NeuralNetFastAI_r4_BAG_L1': ['NeuralNetFastAI_r4_BAG_L1'],\n",
       "  'ExtraTrees_r126_BAG_L1': ['ExtraTrees_r126_BAG_L1'],\n",
       "  'NeuralNetTorch_r36_BAG_L1': ['NeuralNetTorch_r36_BAG_L1'],\n",
       "  'NeuralNetFastAI_r100_BAG_L1': ['NeuralNetFastAI_r100_BAG_L1'],\n",
       "  'CatBoost_r163_BAG_L1': ['CatBoost_r163_BAG_L1'],\n",
       "  'CatBoost_r198_BAG_L1': ['CatBoost_r198_BAG_L1'],\n",
       "  'NeuralNetFastAI_r187_BAG_L1': ['NeuralNetFastAI_r187_BAG_L1'],\n",
       "  'NeuralNetTorch_r19_BAG_L1': ['NeuralNetTorch_r19_BAG_L1'],\n",
       "  'XGBoost_r95_BAG_L1': ['XGBoost_r95_BAG_L1'],\n",
       "  'XGBoost_r34_BAG_L1': ['XGBoost_r34_BAG_L1'],\n",
       "  'LightGBM_r42_BAG_L1': ['LightGBM_r42_BAG_L1'],\n",
       "  'NeuralNetTorch_r1_BAG_L1': ['NeuralNetTorch_r1_BAG_L1'],\n",
       "  'NeuralNetTorch_r89_BAG_L1': ['NeuralNetTorch_r89_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2']},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.44262170791625977,\n",
       "  'KNeighborsDist_BAG_L1': 0.03928685188293457,\n",
       "  'LightGBMXT_BAG_L1': 25.764438152313232,\n",
       "  'LightGBM_BAG_L1': 27.52660608291626,\n",
       "  'RandomForestGini_BAG_L1': 5.676185607910156,\n",
       "  'RandomForestEntr_BAG_L1': 5.7697131633758545,\n",
       "  'CatBoost_BAG_L1': 169.08465361595154,\n",
       "  'ExtraTreesGini_BAG_L1': 3.8108866214752197,\n",
       "  'ExtraTreesEntr_BAG_L1': 3.8457512855529785,\n",
       "  'NeuralNetFastAI_BAG_L1': 116.7879798412323,\n",
       "  'XGBoost_BAG_L1': 26.199342489242554,\n",
       "  'NeuralNetTorch_BAG_L1': 103.65360355377197,\n",
       "  'LightGBMLarge_BAG_L1': 38.925817012786865,\n",
       "  'CatBoost_r177_BAG_L1': 95.23788833618164,\n",
       "  'NeuralNetTorch_r79_BAG_L1': 130.70464706420898,\n",
       "  'LightGBM_r131_BAG_L1': 60.905412435531616,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 278.5942392349243,\n",
       "  'CatBoost_r9_BAG_L1': 100.73698544502258,\n",
       "  'LightGBM_r96_BAG_L1': 61.56179094314575,\n",
       "  'NeuralNetTorch_r22_BAG_L1': 158.51154565811157,\n",
       "  'XGBoost_r33_BAG_L1': 63.02531957626343,\n",
       "  'ExtraTrees_r42_BAG_L1': 5.798694372177124,\n",
       "  'CatBoost_r137_BAG_L1': 180.52802062034607,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 44.78597855567932,\n",
       "  'CatBoost_r13_BAG_L1': 334.7022190093994,\n",
       "  'RandomForest_r195_BAG_L1': 12.144714117050171,\n",
       "  'LightGBM_r188_BAG_L1': 37.76745367050171,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 282.5759308338165,\n",
       "  'XGBoost_r89_BAG_L1': 28.390939474105835,\n",
       "  'NeuralNetTorch_r30_BAG_L1': 171.2455015182495,\n",
       "  'LightGBM_r130_BAG_L1': 27.64321494102478,\n",
       "  'NeuralNetTorch_r86_BAG_L1': 195.79190254211426,\n",
       "  'CatBoost_r50_BAG_L1': 51.89908266067505,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 347.4190442562103,\n",
       "  'XGBoost_r194_BAG_L1': 16.24198818206787,\n",
       "  'ExtraTrees_r172_BAG_L1': 5.72981595993042,\n",
       "  'CatBoost_r69_BAG_L1': 151.41599488258362,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 145.33342671394348,\n",
       "  'NeuralNetTorch_r14_BAG_L1': 62.628944873809814,\n",
       "  'LightGBM_r161_BAG_L1': 86.9534056186676,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 79.28248834609985,\n",
       "  'CatBoost_r70_BAG_L1': 70.34906554222107,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 51.19581913948059,\n",
       "  'LightGBM_r196_BAG_L1': 194.88450384140015,\n",
       "  'RandomForest_r39_BAG_L1': 11.96726131439209,\n",
       "  'CatBoost_r167_BAG_L1': 98.76226139068604,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 304.211688041687,\n",
       "  'NeuralNetTorch_r41_BAG_L1': 102.3562159538269,\n",
       "  'XGBoost_r98_BAG_L1': 97.15950441360474,\n",
       "  'LightGBM_r15_BAG_L1': 42.456687688827515,\n",
       "  'NeuralNetTorch_r158_BAG_L1': 323.839453458786,\n",
       "  'CatBoost_r86_BAG_L1': 203.68780088424683,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 100.98946404457092,\n",
       "  'NeuralNetTorch_r197_BAG_L1': 64.00666499137878,\n",
       "  'CatBoost_r49_BAG_L1': 55.06580853462219,\n",
       "  'ExtraTrees_r49_BAG_L1': 4.021099805831909,\n",
       "  'LightGBM_r143_BAG_L1': 62.88413166999817,\n",
       "  'RandomForest_r127_BAG_L1': 13.949154138565063,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 143.57749319076538,\n",
       "  'RandomForest_r34_BAG_L1': 7.889753103256226,\n",
       "  'LightGBM_r94_BAG_L1': 29.697324752807617,\n",
       "  'NeuralNetTorch_r143_BAG_L1': 231.85974144935608,\n",
       "  'CatBoost_r128_BAG_L1': 81.97706294059753,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 60.666311740875244,\n",
       "  'NeuralNetTorch_r31_BAG_L1': 109.23629784584045,\n",
       "  'ExtraTrees_r4_BAG_L1': 5.07917332649231,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 75.6102545261383,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 74.94378185272217,\n",
       "  'LightGBM_r30_BAG_L1': 88.59565258026123,\n",
       "  'XGBoost_r49_BAG_L1': 38.4601788520813,\n",
       "  'CatBoost_r5_BAG_L1': 156.56853914260864,\n",
       "  'NeuralNetTorch_r87_BAG_L1': 99.32716941833496,\n",
       "  'NeuralNetTorch_r71_BAG_L1': 58.53994965553284,\n",
       "  'CatBoost_r143_BAG_L1': 78.28060722351074,\n",
       "  'ExtraTrees_r178_BAG_L1': 5.210809707641602,\n",
       "  'RandomForest_r166_BAG_L1': 5.578959703445435,\n",
       "  'XGBoost_r31_BAG_L1': 152.80863666534424,\n",
       "  'NeuralNetTorch_r185_BAG_L1': 127.87914633750916,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 211.89430236816406,\n",
       "  'CatBoost_r60_BAG_L1': 127.73452997207642,\n",
       "  'RandomForest_r15_BAG_L1': 11.0708749294281,\n",
       "  'LightGBM_r135_BAG_L1': 40.0167191028595,\n",
       "  'XGBoost_r22_BAG_L1': 30.17425227165222,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 190.5692138671875,\n",
       "  'CatBoost_r6_BAG_L1': 46.64354658126831,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 342.47948002815247,\n",
       "  'LightGBM_r121_BAG_L1': 87.21734762191772,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 72.38538098335266,\n",
       "  'CatBoost_r180_BAG_L1': 59.59649920463562,\n",
       "  'NeuralNetTorch_r76_BAG_L1': 65.9892430305481,\n",
       "  'ExtraTrees_r197_BAG_L1': 7.207674026489258,\n",
       "  'NeuralNetTorch_r121_BAG_L1': 660.6059172153473,\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 57.105770111083984,\n",
       "  'RandomForest_r16_BAG_L1': 16.97446346282959,\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 141.29427909851074,\n",
       "  'CatBoost_r12_BAG_L1': 206.51352906227112,\n",
       "  'NeuralNetTorch_r135_BAG_L1': 148.78916215896606,\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 108.65824055671692,\n",
       "  'ExtraTrees_r126_BAG_L1': 3.548957586288452,\n",
       "  'NeuralNetTorch_r36_BAG_L1': 93.29809498786926,\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 203.29670572280884,\n",
       "  'CatBoost_r163_BAG_L1': 42.812658071517944,\n",
       "  'CatBoost_r198_BAG_L1': 202.80734539031982,\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 66.98534893989563,\n",
       "  'NeuralNetTorch_r19_BAG_L1': 64.83996033668518,\n",
       "  'XGBoost_r95_BAG_L1': 31.743757963180542,\n",
       "  'XGBoost_r34_BAG_L1': 49.31299066543579,\n",
       "  'LightGBM_r42_BAG_L1': 25.38558077812195,\n",
       "  'NeuralNetTorch_r1_BAG_L1': 143.93641138076782,\n",
       "  'NeuralNetTorch_r89_BAG_L1': 137.21523666381836,\n",
       "  'WeightedEnsemble_L2': 3.0733275413513184},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.2511162757873535,\n",
       "  'KNeighborsDist_BAG_L1': 0.25298643112182617,\n",
       "  'LightGBMXT_BAG_L1': 1.8169243335723877,\n",
       "  'LightGBM_BAG_L1': 1.705568552017212,\n",
       "  'RandomForestGini_BAG_L1': 1.2604010105133057,\n",
       "  'RandomForestEntr_BAG_L1': 1.254476547241211,\n",
       "  'CatBoost_BAG_L1': 0.27373433113098145,\n",
       "  'ExtraTreesGini_BAG_L1': 1.3682966232299805,\n",
       "  'ExtraTreesEntr_BAG_L1': 1.3488490581512451,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.9715437889099121,\n",
       "  'XGBoost_BAG_L1': 0.502877950668335,\n",
       "  'NeuralNetTorch_BAG_L1': 0.4065396785736084,\n",
       "  'LightGBMLarge_BAG_L1': 2.6347947120666504,\n",
       "  'CatBoost_r177_BAG_L1': 0.2609889507293701,\n",
       "  'NeuralNetTorch_r79_BAG_L1': 0.4501662254333496,\n",
       "  'LightGBM_r131_BAG_L1': 9.56979513168335,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 1.5666325092315674,\n",
       "  'CatBoost_r9_BAG_L1': 0.42087697982788086,\n",
       "  'LightGBM_r96_BAG_L1': 10.081615447998047,\n",
       "  'NeuralNetTorch_r22_BAG_L1': 0.6620643138885498,\n",
       "  'XGBoost_r33_BAG_L1': 3.8043477535247803,\n",
       "  'ExtraTrees_r42_BAG_L1': 1.3131487369537354,\n",
       "  'CatBoost_r137_BAG_L1': 0.2930474281311035,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.5174081325531006,\n",
       "  'CatBoost_r13_BAG_L1': 0.5681784152984619,\n",
       "  'RandomForest_r195_BAG_L1': 1.2161579132080078,\n",
       "  'LightGBM_r188_BAG_L1': 3.6639792919158936,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 2.251316785812378,\n",
       "  'XGBoost_r89_BAG_L1': 0.4624476432800293,\n",
       "  'NeuralNetTorch_r30_BAG_L1': 0.6882495880126953,\n",
       "  'LightGBM_r130_BAG_L1': 1.961249828338623,\n",
       "  'NeuralNetTorch_r86_BAG_L1': 0.4606349468231201,\n",
       "  'CatBoost_r50_BAG_L1': 0.24615836143493652,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 2.262449264526367,\n",
       "  'XGBoost_r194_BAG_L1': 0.3646354675292969,\n",
       "  'ExtraTrees_r172_BAG_L1': 1.1425502300262451,\n",
       "  'CatBoost_r69_BAG_L1': 0.30974364280700684,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 1.0867383480072021,\n",
       "  'NeuralNetTorch_r14_BAG_L1': 0.30193448066711426,\n",
       "  'LightGBM_r161_BAG_L1': 22.457225799560547,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 0.5586059093475342,\n",
       "  'CatBoost_r70_BAG_L1': 0.32033228874206543,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 0.4938528537750244,\n",
       "  'LightGBM_r196_BAG_L1': 89.24354410171509,\n",
       "  'RandomForest_r39_BAG_L1': 1.1695506572723389,\n",
       "  'CatBoost_r167_BAG_L1': 0.25037050247192383,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 1.8377602100372314,\n",
       "  'NeuralNetTorch_r41_BAG_L1': 0.29683566093444824,\n",
       "  'XGBoost_r98_BAG_L1': 7.454616069793701,\n",
       "  'LightGBM_r15_BAG_L1': 3.9981260299682617,\n",
       "  'NeuralNetTorch_r158_BAG_L1': 0.6772580146789551,\n",
       "  'CatBoost_r86_BAG_L1': 0.36220479011535645,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 1.1548280715942383,\n",
       "  'NeuralNetTorch_r197_BAG_L1': 0.43789219856262207,\n",
       "  'CatBoost_r49_BAG_L1': 0.1415870189666748,\n",
       "  'ExtraTrees_r49_BAG_L1': 1.3693418502807617,\n",
       "  'LightGBM_r143_BAG_L1': 6.525261640548706,\n",
       "  'RandomForest_r127_BAG_L1': 1.0953443050384521,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 1.0415441989898682,\n",
       "  'RandomForest_r34_BAG_L1': 0.9602766036987305,\n",
       "  'LightGBM_r94_BAG_L1': 4.072876930236816,\n",
       "  'NeuralNetTorch_r143_BAG_L1': 0.8088195323944092,\n",
       "  'CatBoost_r128_BAG_L1': 0.3319435119628906,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 0.862959623336792,\n",
       "  'NeuralNetTorch_r31_BAG_L1': 0.408233642578125,\n",
       "  'ExtraTrees_r4_BAG_L1': 1.027083158493042,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 0.5123350620269775,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 0.6340229511260986,\n",
       "  'LightGBM_r30_BAG_L1': 17.91301417350769,\n",
       "  'XGBoost_r49_BAG_L1': 0.9030468463897705,\n",
       "  'CatBoost_r5_BAG_L1': 0.2757408618927002,\n",
       "  'NeuralNetTorch_r87_BAG_L1': 0.39754605293273926,\n",
       "  'NeuralNetTorch_r71_BAG_L1': 0.349290132522583,\n",
       "  'CatBoost_r143_BAG_L1': 0.21257591247558594,\n",
       "  'ExtraTrees_r178_BAG_L1': 1.1575870513916016,\n",
       "  'RandomForest_r166_BAG_L1': 1.24825119972229,\n",
       "  'XGBoost_r31_BAG_L1': 3.244607448577881,\n",
       "  'NeuralNetTorch_r185_BAG_L1': 0.517249584197998,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 2.3107264041900635,\n",
       "  'CatBoost_r60_BAG_L1': 0.2953758239746094,\n",
       "  'RandomForest_r15_BAG_L1': 1.123370885848999,\n",
       "  'LightGBM_r135_BAG_L1': 2.5707454681396484,\n",
       "  'XGBoost_r22_BAG_L1': 0.5351150035858154,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 2.0003583431243896,\n",
       "  'CatBoost_r6_BAG_L1': 0.22224211692810059,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 2.4015045166015625,\n",
       "  'LightGBM_r121_BAG_L1': 21.806471586227417,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 0.7657885551452637,\n",
       "  'CatBoost_r180_BAG_L1': 0.28972959518432617,\n",
       "  'NeuralNetTorch_r76_BAG_L1': 0.3111460208892822,\n",
       "  'ExtraTrees_r197_BAG_L1': 1.2109806537628174,\n",
       "  'NeuralNetTorch_r121_BAG_L1': 2.1638193130493164,\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 0.7593164443969727,\n",
       "  'RandomForest_r16_BAG_L1': 1.1753287315368652,\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 1.3149309158325195,\n",
       "  'CatBoost_r12_BAG_L1': 0.4022684097290039,\n",
       "  'NeuralNetTorch_r135_BAG_L1': 0.5371987819671631,\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 1.0420506000518799,\n",
       "  'ExtraTrees_r126_BAG_L1': 1.219775676727295,\n",
       "  'NeuralNetTorch_r36_BAG_L1': 0.4075205326080322,\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 1.0308270454406738,\n",
       "  'CatBoost_r163_BAG_L1': 0.12621569633483887,\n",
       "  'CatBoost_r198_BAG_L1': 0.41405725479125977,\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 0.6238439083099365,\n",
       "  'NeuralNetTorch_r19_BAG_L1': 0.286571741104126,\n",
       "  'XGBoost_r95_BAG_L1': 0.5107967853546143,\n",
       "  'XGBoost_r34_BAG_L1': 2.326841354370117,\n",
       "  'LightGBM_r42_BAG_L1': 2.4054532051086426,\n",
       "  'NeuralNetTorch_r1_BAG_L1': 0.5409073829650879,\n",
       "  'NeuralNetTorch_r89_BAG_L1': 0.5649542808532715,\n",
       "  'WeightedEnsemble_L2': 0.005347728729248047},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 2,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestGini_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForestEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesGini_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'ExtraTreesEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r177_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r79_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r131_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r191_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r9_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r96_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r22_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r33_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r42_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_r137_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r102_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r13_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r195_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBM_r188_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r145_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r89_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r30_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r130_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r86_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r50_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r11_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r194_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r172_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_r69_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r103_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r14_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r161_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r70_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r156_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r196_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r39_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_r167_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r95_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r41_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r98_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r15_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r158_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r86_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r37_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r197_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBM_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r127_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_r134_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r34_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBM_r94_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r128_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r111_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r31_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r4_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_r65_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r88_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r30_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r5_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r87_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r71_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r178_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForest_r166_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'XGBoost_r31_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r185_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r160_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r60_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r15_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBM_r135_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r22_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r69_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r6_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r138_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r121_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r172_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r180_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r76_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r197_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetTorch_r121_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r127_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r16_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_r194_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r12_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r135_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r4_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r126_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetTorch_r36_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r100_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r163_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r198_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r187_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r19_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r95_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r34_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r42_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r1_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_r89_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                           model  score_val eval_metric  pred_time_val  \\\n",
       " 0           WeightedEnsemble_L2   0.924024     roc_auc       3.762056   \n",
       " 1            CatBoost_r5_BAG_L1   0.923557     roc_auc       0.275741   \n",
       " 2          CatBoost_r177_BAG_L1   0.923550     roc_auc       0.260989   \n",
       " 3           CatBoost_r12_BAG_L1   0.923301     roc_auc       0.402268   \n",
       " 4          CatBoost_r137_BAG_L1   0.923216     roc_auc       0.293047   \n",
       " ..                          ...        ...         ...            ...   \n",
       " 106    RandomForest_r195_BAG_L1   0.908968     roc_auc       1.216158   \n",
       " 107     RandomForest_r16_BAG_L1   0.907693     roc_auc       1.175329   \n",
       " 108  NeuralNetTorch_r158_BAG_L1   0.905820     roc_auc       0.677258   \n",
       " 109       KNeighborsUnif_BAG_L1   0.813516     roc_auc       0.251116   \n",
       " 110       KNeighborsDist_BAG_L1   0.807168     roc_auc       0.252986   \n",
       " \n",
       "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       " 0    990.430052                0.005348           3.073328            2   \n",
       " 1    156.568539                0.275741         156.568539            1   \n",
       " 2     95.237888                0.260989          95.237888            1   \n",
       " 3    206.513529                0.402268         206.513529            1   \n",
       " 4    180.528021                0.293047         180.528021            1   \n",
       " ..          ...                     ...                ...          ...   \n",
       " 106   12.144714                1.216158          12.144714            1   \n",
       " 107   16.974463                1.175329          16.974463            1   \n",
       " 108  323.839453                0.677258         323.839453            1   \n",
       " 109    0.442622                0.251116           0.442622            1   \n",
       " 110    0.039287                0.252986           0.039287            1   \n",
       " \n",
       "      can_infer  fit_order  \n",
       " 0         True        111  \n",
       " 1         True         71  \n",
       " 2         True         14  \n",
       " 3         True         96  \n",
       " 4         True         23  \n",
       " ..         ...        ...  \n",
       " 106       True         26  \n",
       " 107       True         94  \n",
       " 108       True         51  \n",
       " 109       True          1  \n",
       " 110       True          2  \n",
       " \n",
       " [111 rows x 10 columns]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_prof.fit_summary()\n",
    "predictor_student.fit_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ba9dc",
   "metadata": {
    "papermill": {
     "duration": 0.1218,
     "end_time": "2024-11-10T05:05:37.765001",
     "exception": false,
     "start_time": "2024-11-10T05:05:37.643201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd16dd1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T05:05:38.009805Z",
     "iopub.status.busy": "2024-11-10T05:05:38.008425Z",
     "iopub.status.idle": "2024-11-10T05:05:38.048037Z",
     "shell.execute_reply": "2024-11-10T05:05:38.046936Z"
    },
    "papermill": {
     "duration": 0.163074,
     "end_time": "2024-11-10T05:05:38.050647",
     "exception": false,
     "start_time": "2024-11-10T05:05:37.887573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "students : 18772 professionals : 75028\n"
     ]
    }
   ],
   "source": [
    "test_df_student, test_student_id, test_df_professional, test_professional_id = seperate_students (test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d6680ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T05:05:38.291015Z",
     "iopub.status.busy": "2024-11-10T05:05:38.290541Z",
     "iopub.status.idle": "2024-11-10T05:10:30.582819Z",
     "shell.execute_reply": "2024-11-10T05:10:30.581466Z"
    },
    "papermill": {
     "duration": 292.415143,
     "end_time": "2024-11-10T05:10:30.585308",
     "exception": false,
     "start_time": "2024-11-10T05:05:38.170165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 27s, sys: 11.4 s, total: 9min 38s\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "predictions_professional = predictor_prof.predict(test_df_professional.to_pandas () ).round()\n",
    "predictions_student = predictor_student.predict(test_df_student.to_pandas () ).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "019e25cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T05:10:30.896685Z",
     "iopub.status.busy": "2024-11-10T05:10:30.895614Z",
     "iopub.status.idle": "2024-11-10T05:10:30.921796Z",
     "shell.execute_reply": "2024-11-10T05:10:30.920720Z"
    },
    "papermill": {
     "duration": 0.213186,
     "end_time": "2024-11-10T05:10:30.924205",
     "exception": false,
     "start_time": "2024-11-10T05:10:30.711019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌────────┬────────────┐\n",
      "│ id     ┆ Depression │\n",
      "│ ---    ┆ ---        │\n",
      "│ i64    ┆ i64        │\n",
      "╞════════╪════════════╡\n",
      "│ 140700 ┆ 0          │\n",
      "│ 140701 ┆ 0          │\n",
      "│ 140702 ┆ 0          │\n",
      "│ 140704 ┆ 0          │\n",
      "│ 140705 ┆ 0          │\n",
      "└────────┴────────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>by</th><th>len</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>16466</td></tr><tr><td>0</td><td>77334</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌─────┬───────┐\n",
       "│ by  ┆ len   │\n",
       "│ --- ┆ ---   │\n",
       "│ i64 ┆ u32   │\n",
       "╞═════╪═══════╡\n",
       "│ 1   ┆ 16466 │\n",
       "│ 0   ┆ 77334 │\n",
       "└─────┴───────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_professional = test_professional_id.with_columns (pl.Series (predictions_professional).alias ('Depression'))\n",
    "submit_student = test_student_id.with_columns (pl.Series (predictions_student).alias ('Depression'))\n",
    "\n",
    "submission = pl.concat ([submit_professional,submit_student], how = 'vertical' )\n",
    "\n",
    "print (submission.head())\n",
    "\n",
    "submission.group_by(by = 'Depression').len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d8a102a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T05:10:31.176999Z",
     "iopub.status.busy": "2024-11-10T05:10:31.176063Z",
     "iopub.status.idle": "2024-11-10T05:10:31.192371Z",
     "shell.execute_reply": "2024-11-10T05:10:31.191452Z"
    },
    "papermill": {
     "duration": 0.146259,
     "end_time": "2024-11-10T05:10:31.194880",
     "exception": false,
     "start_time": "2024-11-10T05:10:31.048621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.write_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ebece",
   "metadata": {
    "papermill": {
     "duration": 0.12545,
     "end_time": "2024-11-10T05:10:31.457153",
     "exception": false,
     "start_time": "2024-11-10T05:10:31.331703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# cleanup for kaggle to find submission file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cca056ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T05:10:31.709776Z",
     "iopub.status.busy": "2024-11-10T05:10:31.709310Z",
     "iopub.status.idle": "2024-11-10T05:17:49.211390Z",
     "shell.execute_reply": "2024-11-10T05:17:49.210125Z"
    },
    "papermill": {
     "duration": 437.759277,
     "end_time": "2024-11-10T05:17:49.339716",
     "exception": false,
     "start_time": "2024-11-10T05:10:31.580439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted 1906 files in /kaggle/working/Autogluon\n",
      "CPU times: user 7min 5s, sys: 12 s, total: 7min 17s\n",
      "Wall time: 7min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import zipfile\n",
    "\n",
    "def zip_files_in_directory(directory, zip_name):\n",
    "    num_files_deleted = 0 \n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                zipf.write(file_path, os.path.relpath(file_path, directory))\n",
    "                os.remove(file_path)\n",
    "                num_files_deleted += 1\n",
    "    return num_files_deleted  \n",
    "# Example usage\n",
    "directory = '/kaggle/working/Autogluon'\n",
    "zip_name = 'Autogluon.zip'\n",
    "n = zip_files_in_directory(directory, zip_name)\n",
    "\n",
    "print(f\"deleted {n} files in {directory}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10008389,
     "sourceId": 84895,
     "sourceType": "competition"
    },
    {
     "datasetId": 5868381,
     "sourceId": 9616093,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38432.23964,
   "end_time": "2024-11-10T05:17:54.702098",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-09T18:37:22.462458",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
